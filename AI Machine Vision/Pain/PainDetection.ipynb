{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: roboflow in c:\\program files\\python310\\lib\\site-packages (1.1.30)\n",
      "Requirement already satisfied: certifi==2023.7.22 in c:\\program files\\python310\\lib\\site-packages (from roboflow) (2023.7.22)\n",
      "Requirement already satisfied: chardet==4.0.0 in c:\\program files\\python310\\lib\\site-packages (from roboflow) (4.0.0)\n",
      "Requirement already satisfied: cycler==0.10.0 in c:\\program files\\python310\\lib\\site-packages (from roboflow) (0.10.0)\n",
      "Requirement already satisfied: idna==2.10 in c:\\program files\\python310\\lib\\site-packages (from roboflow) (2.10)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\zanyi\\appdata\\roaming\\python\\python310\\site-packages (from roboflow) (1.4.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\zanyi\\appdata\\roaming\\python\\python310\\site-packages (from roboflow) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\zanyi\\appdata\\roaming\\python\\python310\\site-packages (from roboflow) (1.23.4)\n",
      "Requirement already satisfied: opencv-python-headless==4.8.0.74 in c:\\program files\\python310\\lib\\site-packages (from roboflow) (4.8.0.74)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\zanyi\\appdata\\roaming\\python\\python310\\site-packages (from roboflow) (9.4.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\zanyi\\appdata\\roaming\\python\\python310\\site-packages (from roboflow) (2.8.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\zanyi\\appdata\\roaming\\python\\python310\\site-packages (from roboflow) (1.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\zanyi\\appdata\\roaming\\python\\python310\\site-packages (from roboflow) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\zanyi\\appdata\\roaming\\python\\python310\\site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\zanyi\\appdata\\roaming\\python\\python310\\site-packages (from roboflow) (2.0.3)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\zanyi\\appdata\\roaming\\python\\python310\\site-packages (from roboflow) (4.65.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\zanyi\\appdata\\roaming\\python\\python310\\site-packages (from roboflow) (6.0)\n",
      "Requirement already satisfied: requests-toolbelt in c:\\users\\zanyi\\appdata\\roaming\\python\\python310\\site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: python-magic in c:\\users\\zanyi\\appdata\\roaming\\python\\python310\\site-packages (from roboflow) (0.4.27)\n",
      "Requirement already satisfied: colorama in c:\\users\\zanyi\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\zanyi\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->roboflow) (1.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\zanyi\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->roboflow) (4.39.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\zanyi\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->roboflow) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\zanyi\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->roboflow) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\zanyi\\appdata\\roaming\\python\\python310\\site-packages (from requests->roboflow) (2.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.2.28, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in pain-1 to yolov8:: 100%|██████████| 1788/1788 [00:01<00:00, 938.55it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to pain-1 in yolov8:: 100%|██████████| 205/205 [00:00<00:00, 819.84it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"TxIGi1xnNFU9liy45wew\")\n",
    "project = rf.workspace(\"amy\").project(\"pain-0ozah\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(416, 416)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "Image.open(r\"C:\\Users\\zanyi\\OneDrive\\Git hub\\Ai\\AI Machine Vision\\Pain\\pain-1\\train\\images\\001_jpg.rf.3c511dfc302a75d624b12c4fe2a93843.jpg\").size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  no model scale passed. Assuming scale='n'.\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.25M/6.25M [00:04<00:00, 1.39MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred 355/355 items from pretrained weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.48 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.28  Python-3.10.8 torch-2.3.0+cpu CPU (AMD Ryzen 9 4900HS with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8.yaml, data=C:\\Users\\zanyi\\OneDrive\\Git hub\\Ai\\AI Machine Vision\\Pain\\pain-1\\data.yaml, epochs=80, time=None, patience=100, batch=16, imgsz=416, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "WARNING  no model scale passed. Assuming scale='n'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLOv8 summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "ClearML Task: created new task id=cb6241137ffb4569bdf7479dc998be14\n",
      "2024-06-30 10:12:06,646 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "ClearML results page: https://app.clear.ml/projects/34e8998891b1424a97df5324d4dcbc9b/experiments/cb6241137ffb4569bdf7479dc998be14/output/log\n",
      "ClearML Initialized a new task. If you want to run remotely, please add clearml-init and connect your arguments before initializing YOLO.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/hazywho/general/a8bc797dbf21437c842fc7cc196f5fa5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\zanyi\\OneDrive\\Git hub\\Ai\\AI Machine Vision\\Pain\\pain-1\\train\\labels... 68 images, 0 backgrounds, 0 corrupt: 100%|██████████| 68/68 [00:00<00:00, 207.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\zanyi\\OneDrive\\Git hub\\Ai\\AI Machine Vision\\Pain\\pain-1\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\zanyi\\OneDrive\\Git hub\\Ai\\AI Machine Vision\\Pain\\pain-1\\valid\\labels... 30 images, 0 backgrounds, 0 corrupt: 100%|██████████| 30/30 [00:00<00:00, 398.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\zanyi\\OneDrive\\Git hub\\Ai\\AI Machine Vision\\Pain\\pain-1\\valid\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 416 train, 416 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train\u001b[0m\n",
      "Starting training for 80 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/80         0G       2.99      5.013       2.45          7        416: 100%|██████████| 5/5 [00:27<00:00,  5.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32   0.000114     0.0312   5.92e-05   1.77e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/80         0G      2.844      4.588      2.252          5        416: 100%|██████████| 5/5 [00:50<00:00, 10.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:10<00:00, 10.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32   0.000113     0.0312   6.53e-05   1.28e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/80         0G      2.241      3.891      1.808          5        416: 100%|██████████| 5/5 [01:14<00:00, 14.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:26<00:00, 26.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32   0.000556      0.156   0.000403   0.000135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/80         0G      1.703      2.693      1.496          3        416: 100%|██████████| 5/5 [01:50<00:00, 22.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:33<00:00, 33.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.002      0.562     0.0046    0.00182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/80         0G      1.796      2.215      1.411          8        416: 100%|██████████| 5/5 [01:32<00:00, 18.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32    0.00222      0.625    0.00544    0.00208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/80         0G      1.673      2.309      1.397          4        416: 100%|██████████| 5/5 [00:27<00:00,  5.52s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32    0.00222      0.625    0.00508    0.00172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/80         0G      1.566      2.093      1.365          4        416: 100%|██████████| 5/5 [00:25<00:00,  5.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32    0.00233      0.656    0.00521    0.00237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/80         0G      1.724      1.871      1.386          7        416: 100%|██████████| 5/5 [00:25<00:00,  5.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32    0.00256      0.719    0.00568    0.00192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/80         0G      1.618      1.724      1.332          5        416: 100%|██████████| 5/5 [00:25<00:00,  5.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32    0.00311      0.875     0.0366     0.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/80         0G      1.521      1.649        1.3          5        416: 100%|██████████| 5/5 [00:25<00:00,  5.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32    0.00289      0.812      0.133     0.0494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/80         0G      1.534      1.856      1.316          3        416: 100%|██████████| 5/5 [00:25<00:00,  5.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32    0.00267       0.75     0.0564     0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/80         0G      1.622      1.728      1.318          3        416: 100%|██████████| 5/5 [00:25<00:00,  5.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.003      0.844       0.19     0.0838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/80         0G      1.597      1.562      1.338          8        416: 100%|██████████| 5/5 [00:25<00:00,  5.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:05<00:00,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.003      0.844      0.219      0.126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/80         0G      1.625      1.527      1.353          7        416: 100%|██████████| 5/5 [00:25<00:00,  5.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32          1     0.0659      0.381      0.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/80         0G      1.631      1.461      1.341          5        416: 100%|██████████| 5/5 [00:26<00:00,  5.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32          1      0.132       0.57      0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/80         0G      1.599      1.595      1.382          4        416: 100%|██████████| 5/5 [00:24<00:00,  4.94s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.881      0.125      0.545      0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/80         0G      1.686       1.53      1.439          4        416: 100%|██████████| 5/5 [00:23<00:00,  4.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.865      0.202      0.639      0.296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/80         0G      1.538      1.257      1.314          6        416: 100%|██████████| 5/5 [00:23<00:00,  4.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.757      0.196      0.647      0.275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/80         0G      1.563      1.451      1.372          4        416: 100%|██████████| 5/5 [00:23<00:00,  4.62s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.683       0.25      0.589      0.247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/80         0G      1.468       1.39      1.277         11        416: 100%|██████████| 5/5 [00:22<00:00,  4.51s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32       0.95      0.596      0.772      0.336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/80         0G      1.433      1.302      1.316          6        416: 100%|██████████| 5/5 [00:21<00:00,  4.36s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.909      0.562      0.758      0.339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/80         0G      1.391      1.264      1.275          3        416: 100%|██████████| 5/5 [00:21<00:00,  4.38s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.949      0.625      0.763      0.349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/80         0G      1.383      1.145      1.218          4        416: 100%|██████████| 5/5 [00:21<00:00,  4.38s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.955      0.594        0.8      0.316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/80         0G      1.443      1.261      1.342          4        416: 100%|██████████| 5/5 [00:22<00:00,  4.40s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.713      0.594      0.624      0.279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/80         0G      1.401      1.205      1.248          6        416: 100%|██████████| 5/5 [00:21<00:00,  4.35s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.767      0.531      0.661      0.299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/80         0G      1.385      1.231      1.215          5        416: 100%|██████████| 5/5 [00:21<00:00,  4.37s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.805      0.645      0.706      0.313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/80         0G       1.33      1.264      1.253          6        416: 100%|██████████| 5/5 [00:21<00:00,  4.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.832      0.719      0.762      0.343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/80         0G      1.363      1.062      1.239         10        416: 100%|██████████| 5/5 [00:21<00:00,  4.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.923      0.749      0.832      0.367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/80         0G      1.264      1.063      1.181          4        416: 100%|██████████| 5/5 [00:21<00:00,  4.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.932      0.719      0.824      0.372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/80         0G      1.615      1.419      1.421          2        416: 100%|██████████| 5/5 [00:21<00:00,  4.37s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.988      0.719      0.807      0.408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/80         0G      1.291      1.143      1.269          7        416: 100%|██████████| 5/5 [00:23<00:00,  4.72s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32          1      0.645      0.767      0.368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/80         0G      1.369      1.017      1.243          8        416: 100%|██████████| 5/5 [00:23<00:00,  4.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.863      0.592      0.708      0.346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/80         0G      1.265      1.015      1.257          4        416: 100%|██████████| 5/5 [00:28<00:00,  5.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.859      0.562      0.721      0.338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/80         0G      1.346      1.074      1.198          5        416: 100%|██████████| 5/5 [00:26<00:00,  5.26s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.892      0.625      0.722      0.305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/80         0G      1.129     0.9451       1.14          7        416: 100%|██████████| 5/5 [00:22<00:00,  4.55s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.701      0.531      0.636      0.282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/80         0G      1.268      1.029      1.186          6        416: 100%|██████████| 5/5 [00:22<00:00,  4.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.724      0.531      0.622      0.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/80         0G      1.227     0.9809      1.146          3        416: 100%|██████████| 5/5 [00:22<00:00,  4.54s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.989      0.562       0.71       0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/80         0G      1.188     0.9618       1.14          7        416: 100%|██████████| 5/5 [00:22<00:00,  4.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.934      0.656      0.782      0.282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/80         0G      1.098     0.9449      1.137         11        416: 100%|██████████| 5/5 [00:22<00:00,  4.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.772      0.719       0.81      0.327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/80         0G      1.138     0.9254      1.143         10        416: 100%|██████████| 5/5 [00:24<00:00,  4.95s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.916      0.678      0.823      0.388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/80         0G      1.202       1.07      1.222          6        416: 100%|██████████| 5/5 [00:22<00:00,  4.54s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.955      0.669      0.848      0.408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/80         0G      1.093     0.9292      1.117          5        416: 100%|██████████| 5/5 [00:23<00:00,  4.75s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.874      0.844      0.898      0.415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/80         0G      1.191     0.9672      1.138          6        416: 100%|██████████| 5/5 [00:23<00:00,  4.64s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.931      0.849      0.917      0.365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/80         0G      1.275     0.9172       1.22          6        416: 100%|██████████| 5/5 [00:22<00:00,  4.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32        0.9      0.843      0.905      0.388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/80         0G      1.252     0.9123      1.207          3        416: 100%|██████████| 5/5 [00:22<00:00,  4.49s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32       0.96      0.812      0.911      0.416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/80         0G      1.186     0.8983      1.181          3        416: 100%|██████████| 5/5 [00:23<00:00,  4.65s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.958      0.812      0.911      0.424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/80         0G      1.163     0.8636      1.165          6        416: 100%|██████████| 5/5 [00:24<00:00,  4.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.928      0.844      0.926       0.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/80         0G      1.202      1.052      1.172          5        416: 100%|██████████| 5/5 [00:23<00:00,  4.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.946      0.906      0.943      0.407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/80         0G      1.085     0.8678      1.102          3        416: 100%|██████████| 5/5 [00:23<00:00,  4.69s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.938      0.812      0.918       0.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/80         0G      1.095     0.8159      1.098          7        416: 100%|██████████| 5/5 [00:22<00:00,  4.59s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32          1      0.781       0.89      0.361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      51/80         0G      1.166     0.9705      1.159          2        416: 100%|██████████| 5/5 [00:23<00:00,  4.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.963      0.806      0.881      0.374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      52/80         0G      1.177     0.9531      1.191          9        416: 100%|██████████| 5/5 [00:23<00:00,  4.69s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.958      0.714      0.834      0.369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      53/80         0G      1.211      1.033      1.186          5        416: 100%|██████████| 5/5 [00:25<00:00,  5.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.958      0.719      0.831      0.352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      54/80         0G      1.171     0.8068       1.09          9        416: 100%|██████████| 5/5 [00:23<00:00,  4.63s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.962      0.781      0.892      0.342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      55/80         0G      1.022     0.7481      1.037          5        416: 100%|██████████| 5/5 [00:24<00:00,  4.83s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32          1      0.775      0.895      0.363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      56/80         0G      1.063     0.7886      1.114          5        416: 100%|██████████| 5/5 [00:23<00:00,  4.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32          1      0.833      0.919      0.415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      57/80         0G      1.025     0.7814      1.087          7        416: 100%|██████████| 5/5 [00:23<00:00,  4.75s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:05<00:00,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32          1      0.838      0.924      0.429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      58/80         0G      1.041     0.7673      1.082          5        416: 100%|██████████| 5/5 [00:24<00:00,  4.83s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.927      0.844      0.925      0.444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      59/80         0G      1.076     0.8343      1.132          6        416: 100%|██████████| 5/5 [00:24<00:00,  4.95s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.933      0.867      0.929      0.459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      60/80         0G     0.9914     0.7236      1.046          5        416: 100%|██████████| 5/5 [00:22<00:00,  4.57s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.892      0.875      0.929       0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      61/80         0G      1.016     0.7206      1.014          9        416: 100%|██████████| 5/5 [00:22<00:00,  4.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.903      0.876      0.933      0.445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      62/80         0G     0.9503     0.8458      1.091          4        416: 100%|██████████| 5/5 [00:23<00:00,  4.72s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.903      0.906      0.939      0.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      63/80         0G     0.9975     0.7138      1.004          6        416: 100%|██████████| 5/5 [00:22<00:00,  4.43s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.966      0.879      0.941      0.453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      64/80         0G     0.9943     0.7762      1.069          8        416: 100%|██████████| 5/5 [00:28<00:00,  5.64s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.961      0.906      0.941      0.441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      65/80         0G      1.058     0.6946      1.032          3        416: 100%|██████████| 5/5 [00:25<00:00,  5.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:05<00:00,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.967      0.902      0.942      0.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      66/80         0G     0.9602      0.722       1.06          7        416: 100%|██████████| 5/5 [00:23<00:00,  4.77s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.966      0.898      0.941      0.446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      67/80         0G      1.047     0.8163      1.085          6        416: 100%|██████████| 5/5 [00:24<00:00,  4.95s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32          1      0.903      0.949      0.454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      68/80         0G      1.127     0.7338      1.065          4        416: 100%|██████████| 5/5 [00:24<00:00,  4.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32          1      0.897      0.943      0.442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      69/80         0G     0.9154     0.6961      1.016         10        416: 100%|██████████| 5/5 [00:24<00:00,  4.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.997      0.906      0.953      0.437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      70/80         0G     0.9343     0.6959      1.001          3        416: 100%|██████████| 5/5 [00:23<00:00,  4.62s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.953      0.875      0.949       0.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      71/80         0G     0.9365     0.7287      1.093          4        416: 100%|██████████| 5/5 [00:23<00:00,  4.74s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.965      0.875      0.954      0.429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      72/80         0G     0.8619     0.6991      0.987          4        416: 100%|██████████| 5/5 [00:26<00:00,  5.36s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:05<00:00,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32       0.95      0.844      0.949      0.444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      73/80         0G     0.7919      0.644     0.9716          4        416: 100%|██████████| 5/5 [00:25<00:00,  5.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.952      0.844       0.95      0.454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      74/80         0G     0.8147     0.6959      1.028          4        416: 100%|██████████| 5/5 [00:24<00:00,  4.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.954      0.844      0.947      0.455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      75/80         0G     0.8666      0.704       1.02          4        416: 100%|██████████| 5/5 [00:24<00:00,  4.95s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.956      0.844      0.946       0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      76/80         0G     0.9298     0.6948      1.061          4        416: 100%|██████████| 5/5 [00:25<00:00,  5.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:05<00:00,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.958      0.844      0.947      0.456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      77/80         0G     0.7322      0.687      0.977          4        416: 100%|██████████| 5/5 [00:25<00:00,  5.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.957      0.844      0.949      0.458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      78/80         0G     0.7602     0.6536      0.992          4        416: 100%|██████████| 5/5 [00:24<00:00,  4.98s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.957      0.844      0.949      0.448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      79/80         0G     0.7857     0.6474     0.9844          4        416: 100%|██████████| 5/5 [00:29<00:00,  5.94s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.961      0.844      0.949      0.447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      80/80         0G     0.8613     0.6115      1.012          4        416: 100%|██████████| 5/5 [00:25<00:00,  5.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.957      0.844      0.946      0.442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "80 epochs completed in 0.735 hours.\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.28  Python-3.10.8 torch-2.3.0+cpu CPU (AMD Ryzen 9 4900HS with Radeon Graphics)\n",
      "YOLOv8 summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30         32      0.955      0.844      0.946       0.47\n",
      "Speed: 2.2ms preprocess, 143.4ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train\u001b[0m\n",
      "2024-06-30 10:57:25,304 - clearml.storage - INFO - Starting upload: runs\\detect\\train\\weights\\best.pt => https://files.clear.ml/YOLOv8/train.cb6241137ffb4569bdf7479dc998be14/models/best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/hazywho/general/a8bc797dbf21437c842fc7cc196f5fa5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [161]               : (4.4749999999999915e-05, 0.0015144525)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [161]               : (4.4749999999999915e-05, 0.0015144525)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [161]               : (4.4749999999999915e-05, 0.0015144525)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B) [162]     : (6e-05, 0.95361)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [162]  : (1e-05, 0.47013)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [162] : (0.00011, 1.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B) [162]    : (0.03125, 0.90625)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs               : 8.194\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters           : 3011043\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)    : 163.477\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [160]       : (0.73219, 2.98956)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [160]       : (0.61147, 5.01258)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [160]       : (0.9716, 2.44969)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [160]         : (1.6878, 3.18659)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [160]         : (1.01357, 5.39947)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [160]         : (1.38862, 2.64474)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : C:\\Users\\zanyi\\OneDrive\\Git hub\\Ai\\AI Machine Vision\\Pain\\pain-1\\data.yaml\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 80\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 416\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     label_smoothing : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : yolov8.yaml\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs\\detect\\train\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : detect\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed) : 1 (2.92 MB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images                   : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element            : 1 (5.94 MB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 9 file(s), remaining 6.01 MB/7.95 MB\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 2.83 MB/7.95 MB, Throughput 214.81 KB/s, ETA ~14s\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 766.10 KB/7.95 MB, Throughput 140.11 KB/s, ETA ~6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001B0A77CE0B0>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.96429,\n",
       "            0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,\n",
       "            0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,\n",
       "            0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,\n",
       "            0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,\n",
       "            0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,\n",
       "            0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.82857,     0.81081,     0.81081,     0.81081,     0.81081,     0.81081,     0.81081,     0.81081,     0.81081,     0.81081,     0.81081,     0.81081,     0.81081,     0.81081,     0.81081,\n",
       "            0.81081,     0.81081,     0.81081,     0.81081,     0.81081,     0.81081,     0.81081,     0.81081,     0.81081,     0.81081,     0.81081,     0.81081,     0.81081,     0.81081,     0.81081,     0.81081,     0.81081,     0.56364,     0.56364,     0.56364,     0.56364,     0.56364,     0.56364,\n",
       "            0.56364,     0.56364,     0.56364,     0.56364,     0.56364,     0.56364,     0.56364,     0.56364,     0.56364,     0.56364,     0.56364,     0.56364,     0.56364,     0.56364,     0.56364,     0.56364,     0.56364,     0.56364,     0.56364,     0.56364,     0.56364,     0.56364,     0.56364,\n",
       "            0.56364,     0.56364,     0.42105,     0.42105,     0.42105,     0.42105,     0.42105,     0.42105,     0.42105,     0.42105,     0.42105,     0.42105,     0.42105,     0.42105,     0.42105,     0.42105,     0.42105,     0.42105,     0.42105,     0.42105,     0.42105,     0.42105,     0.42105,\n",
       "            0.42105,     0.42105,     0.42105,     0.42105,     0.42105,     0.42105,     0.42105,     0.42105,     0.42105,     0.42105,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.015814,    0.015821,    0.021582,     0.38504,     0.49305,     0.56123,     0.58714,      0.6052,     0.62866,     0.64281,     0.65234,     0.66635,     0.69493,      0.7054,      0.7123,     0.71578,      0.7275,     0.73641,     0.74124,     0.74227,      0.7433,     0.74432,     0.74535,\n",
       "            0.74637,     0.74739,     0.74841,     0.74943,     0.76029,     0.76226,     0.76422,     0.76618,     0.76812,     0.78086,     0.78509,     0.78928,     0.80498,      0.8239,     0.82823,     0.83253,     0.83556,     0.83829,       0.841,     0.84371,     0.84554,     0.84649,     0.84743,\n",
       "            0.84838,     0.84932,     0.85026,      0.8512,     0.85214,     0.85307,     0.85401,     0.85494,     0.85587,      0.8568,     0.85782,     0.85889,     0.85996,     0.86103,     0.86209,     0.86315,     0.86421,     0.86527,     0.86633,     0.86738,     0.86843,     0.86948,      0.8688,\n",
       "            0.86797,     0.86714,     0.86631,     0.86548,     0.86464,     0.86381,     0.86297,     0.86214,      0.8613,     0.86046,     0.85962,     0.85878,     0.85794,      0.8571,     0.85626,     0.85542,     0.85457,     0.85373,     0.85302,     0.85419,     0.85536,     0.85653,      0.8577,\n",
       "            0.85886,     0.86002,     0.86118,     0.86233,     0.86348,     0.86463,     0.86463,     0.85312,      0.8481,     0.84745,      0.8468,     0.84615,      0.8455,     0.84485,      0.8442,     0.84354,     0.84289,     0.84224,     0.84159,     0.84093,     0.84028,     0.83962,     0.83897,\n",
       "            0.83831,     0.83766,       0.837,     0.83634,     0.83569,     0.83503,     0.83437,     0.83371,     0.83305,     0.83239,     0.83173,     0.83107,     0.83139,     0.83252,     0.83364,     0.83477,     0.83589,       0.837,     0.83812,     0.83923,     0.84034,     0.84144,     0.84254,\n",
       "            0.84364,     0.84563,      0.8477,     0.84976,     0.85181,     0.85385,     0.85588,     0.85798,     0.86018,     0.86237,     0.86455,     0.86672,     0.86887,     0.87097,     0.87124,     0.87151,     0.87178,     0.87205,     0.87232,     0.87259,     0.87285,     0.87312,     0.87339,\n",
       "            0.87366,     0.87392,     0.87419,     0.87446,     0.87472,     0.87499,     0.87526,     0.87552,     0.87579,     0.87605,     0.87632,     0.87659,     0.87685,     0.87712,     0.87738,     0.87765,     0.87791,     0.87817,     0.87844,      0.8787,     0.87897,     0.87923,     0.87949,\n",
       "            0.87976,     0.88002,     0.88028,     0.88055,     0.88081,     0.88107,     0.88133,      0.8816,     0.88186,     0.88212,     0.88238,     0.88264,      0.8829,     0.88317,     0.88343,     0.88369,     0.88395,     0.88421,     0.88447,     0.88473,     0.88499,     0.88525,     0.88533,\n",
       "            0.88541,     0.88549,     0.88557,     0.88565,     0.88573,     0.88581,     0.88589,     0.88597,     0.88605,     0.88613,     0.88621,     0.88629,     0.88637,     0.88645,     0.88652,      0.8866,     0.88668,     0.88676,     0.88684,     0.88692,       0.887,     0.88708,     0.88716,\n",
       "            0.88724,     0.88732,      0.8874,     0.88748,     0.88756,     0.88764,     0.88772,      0.8878,     0.88788,     0.88796,     0.88804,     0.88812,      0.8882,     0.88828,     0.88836,     0.88843,     0.88851,     0.88859,     0.88867,     0.88875,     0.88883,     0.88891,     0.88899,\n",
       "            0.88907,     0.88915,     0.88923,     0.88931,     0.88939,     0.88947,     0.88954,     0.88962,      0.8897,     0.88978,     0.88986,     0.88994,     0.89002,      0.8901,     0.89018,     0.89026,     0.89034,     0.89041,     0.89049,     0.89057,     0.89065,     0.89073,     0.89081,\n",
       "            0.89089,     0.89097,     0.89105,     0.89112,      0.8912,     0.89128,     0.89136,     0.89144,     0.89152,      0.8916,     0.89168,     0.89175,     0.89183,     0.89191,     0.89199,     0.89207,     0.89215,     0.89223,     0.89231,     0.89238,     0.89246,     0.89254,     0.89262,\n",
       "             0.8927,     0.89278,     0.89286,     0.89293,     0.89301,     0.89309,     0.89317,     0.89325,     0.89333,      0.8934,     0.89348,     0.89356,     0.89364,     0.89372,      0.8938,     0.89387,     0.89395,     0.89403,     0.89411,     0.89419,     0.89427,     0.89434,     0.89442,\n",
       "             0.8945,     0.89458,     0.89466,     0.89473,     0.89481,     0.89489,     0.89497,     0.89505,     0.89513,      0.8952,     0.89528,     0.89536,     0.89544,     0.89552,     0.89559,     0.89567,     0.89575,     0.89583,      0.8959,     0.89598,     0.89606,     0.89614,     0.89622,\n",
       "            0.89629,     0.89637,     0.89645,     0.89653,     0.89661,     0.89668,     0.89676,     0.89684,     0.89692,     0.89699,     0.89707,     0.89715,     0.89723,      0.8973,     0.89738,     0.89746,     0.89754,     0.89761,     0.89769,     0.89777,     0.89785,     0.89793,       0.898,\n",
       "            0.89808,     0.89816,     0.89824,     0.89831,     0.89839,     0.89847,     0.89854,     0.89862,      0.8987,     0.89878,     0.89885,     0.89893,     0.89901,     0.89909,     0.89916,     0.89924,     0.89932,     0.89939,     0.89947,     0.89955,     0.89963,      0.8997,     0.89978,\n",
       "            0.89986,     0.89994,     0.89859,     0.88957,     0.88131,     0.88087,     0.88042,     0.87998,     0.87953,     0.87909,     0.87864,      0.8782,     0.87775,      0.8773,     0.87686,     0.87641,     0.87596,     0.87551,     0.87506,     0.87462,     0.87417,     0.87372,     0.87327,\n",
       "            0.87282,     0.87237,     0.87192,     0.87147,     0.87101,     0.87056,     0.87011,     0.86966,     0.86921,     0.86875,      0.8683,     0.86785,     0.86739,     0.86694,     0.86648,     0.86603,     0.86557,     0.86512,     0.86466,      0.8642,     0.86375,     0.86329,     0.86283,\n",
       "            0.86237,     0.86211,     0.86225,     0.86238,     0.86252,     0.86265,     0.86279,     0.86292,     0.86306,     0.86319,     0.86332,     0.86346,     0.86359,     0.86373,     0.86386,       0.864,     0.86413,     0.86426,      0.8644,     0.86453,     0.86467,      0.8648,     0.86493,\n",
       "            0.86507,      0.8652,     0.86533,     0.86547,      0.8656,     0.86573,     0.86587,       0.866,     0.86613,     0.86627,      0.8664,     0.86653,     0.86667,      0.8668,     0.86693,     0.86707,      0.8672,     0.86733,     0.86746,      0.8676,     0.86773,     0.86786,     0.86799,\n",
       "            0.86813,     0.86826,     0.86839,     0.86852,     0.86866,     0.86879,     0.86892,     0.86905,     0.86919,     0.86932,     0.86945,     0.86958,     0.86971,     0.86984,     0.86998,     0.87011,     0.87024,     0.87037,      0.8705,     0.87063,     0.87077,      0.8709,     0.87103,\n",
       "            0.87116,     0.87129,     0.87142,     0.87155,     0.87169,     0.87182,     0.87195,     0.87208,     0.87221,     0.87234,     0.87247,      0.8726,     0.87273,     0.87286,     0.87299,     0.87312,     0.87326,     0.87339,     0.87352,     0.87365,     0.87378,     0.87391,     0.87404,\n",
       "            0.87417,      0.8743,     0.87443,     0.87456,     0.87469,     0.87482,     0.87495,     0.87508,     0.87521,     0.87534,     0.87547,      0.8756,     0.87573,     0.87586,     0.87599,     0.87612,     0.87624,     0.87637,      0.8765,     0.87663,     0.87676,     0.87689,     0.87702,\n",
       "            0.87715,     0.87663,     0.87579,     0.87494,     0.87409,     0.87324,     0.87238,     0.87153,     0.87067,     0.86982,     0.86896,      0.8681,     0.86724,     0.86638,     0.86551,     0.86465,     0.86378,     0.86291,     0.86205,     0.86118,      0.8603,     0.85943,     0.85856,\n",
       "            0.85768,     0.85702,      0.8567,     0.85638,     0.85606,     0.85574,     0.85542,      0.8551,     0.85478,     0.85446,     0.85413,     0.85381,     0.85349,     0.85317,     0.85285,     0.85253,      0.8522,     0.85188,     0.85156,     0.85123,     0.85091,     0.85059,     0.85026,\n",
       "            0.84994,     0.84962,     0.84929,     0.84897,     0.84864,     0.84832,       0.848,     0.84767,     0.84735,     0.84702,     0.84669,     0.84637,     0.84604,     0.84572,     0.84539,     0.84506,     0.84474,     0.84441,     0.84408,     0.84376,     0.84343,      0.8431,     0.84277,\n",
       "            0.84245,     0.84212,     0.84179,     0.84146,     0.84113,      0.8408,     0.84047,     0.84015,     0.83982,     0.83949,     0.83916,     0.83883,      0.8385,     0.83817,     0.83784,      0.8375,     0.83717,     0.83684,     0.83651,     0.82926,     0.81621,     0.80874,     0.80187,\n",
       "            0.79492,     0.79195,     0.79118,      0.7904,     0.78963,     0.78885,     0.78807,     0.78729,     0.78651,     0.78573,     0.78495,     0.78416,     0.78338,      0.7826,     0.78181,     0.78102,     0.78023,     0.77944,     0.77865,     0.77786,     0.77707,     0.77628,     0.77548,\n",
       "            0.77469,     0.77389,     0.77309,     0.77229,     0.77149,     0.77069,     0.76989,     0.76893,     0.76723,     0.76552,     0.76381,      0.7621,     0.76038,     0.75865,     0.75692,     0.75518,     0.75344,      0.7517,     0.74995,     0.74819,     0.74643,     0.74282,     0.73333,\n",
       "            0.72369,     0.71897,     0.71731,     0.71564,     0.71397,      0.7123,     0.71062,     0.70893,     0.70724,     0.70555,     0.70386,     0.70215,     0.70045,     0.69874,     0.69702,      0.6953,     0.69344,     0.69089,     0.68834,     0.68578,      0.6832,     0.68062,     0.67802,\n",
       "            0.67542,      0.6728,     0.67017,     0.66754,     0.66363,     0.65907,     0.65448,     0.64986,     0.64521,     0.64053,     0.62659,     0.60689,     0.59836,     0.58971,     0.58096,     0.57358,     0.56697,      0.5603,     0.55356,     0.54676,      0.5448,     0.54398,     0.54317,\n",
       "            0.54235,     0.54154,     0.54072,      0.5399,     0.53909,     0.53827,     0.53745,     0.53662,      0.5358,     0.53498,     0.53415,     0.53333,      0.5325,     0.53168,     0.53085,     0.53002,     0.52919,     0.52836,     0.52753,     0.52669,     0.52586,     0.52503,     0.52419,\n",
       "            0.52335,     0.52252,     0.52168,     0.52084,        0.52,     0.51916,     0.51831,     0.51747,     0.51663,     0.51578,     0.51494,     0.51409,     0.51324,     0.51239,     0.51152,     0.51043,     0.50935,     0.50826,     0.50717,     0.50608,     0.50499,     0.50389,      0.5028,\n",
       "             0.5017,      0.5006,      0.4995,      0.4984,     0.49729,     0.49619,     0.49508,     0.49397,     0.49286,     0.49175,     0.49063,     0.48952,      0.4884,     0.48728,     0.48616,     0.48504,     0.48392,     0.48279,     0.48166,     0.48053,      0.4794,     0.47827,     0.47714,\n",
       "            0.47198,     0.44597,     0.43798,     0.43656,     0.43514,     0.43372,     0.43229,     0.43086,     0.42943,       0.428,     0.42656,     0.42512,     0.42368,     0.42224,     0.42079,     0.41934,     0.41789,     0.41643,     0.41498,     0.41352,     0.41205,     0.41059,     0.40912,\n",
       "            0.40765,     0.40618,      0.4047,     0.40322,     0.40174,     0.40025,     0.39158,     0.38131,     0.37091,     0.36038,     0.33469,     0.31451,     0.31077,     0.30702,     0.30325,     0.29946,     0.29565,     0.29183,     0.28798,     0.28413,     0.28025,     0.27636,     0.27245,\n",
       "            0.25691,     0.22615,      0.2041,     0.18293,     0.17054,     0.16864,     0.16674,     0.16483,     0.16292,       0.161,     0.15908,     0.15715,     0.15523,     0.15329,     0.15136,     0.14942,     0.14747,     0.14552,     0.14357,     0.14161,     0.13965,     0.13768,     0.13571,\n",
       "            0.13374,     0.13176,     0.12978,     0.12779,      0.1258,     0.12381,     0.12181,     0.11981,      0.1178,     0.11661,     0.11549,     0.11436,     0.11324,     0.11211,     0.11098,     0.10985,     0.10872,     0.10759,     0.10646,     0.10532,     0.10419,     0.10305,     0.10191,\n",
       "            0.10077,    0.099629,    0.098486,    0.097342,    0.096196,    0.095049,      0.0939,    0.092751,    0.091599,    0.090447,    0.089293,    0.088137,    0.086981,    0.085822,    0.084663,    0.083502,    0.082339,    0.081175,     0.08001,    0.078843,    0.077675,    0.076506,    0.075335,\n",
       "           0.074162,    0.072989,    0.071813,    0.070637,    0.069459,    0.068279,    0.067098,    0.065916,    0.064732,    0.063547,     0.06236,    0.061172,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[  0.0079701,   0.0079733,    0.010909,     0.23842,     0.32718,     0.39008,     0.41556,     0.44006,     0.46531,     0.48098,     0.49173,     0.50783,     0.54179,     0.55463,     0.56321,     0.57888,     0.59436,     0.60635,     0.61293,     0.61434,     0.61575,     0.61716,     0.61856,\n",
       "            0.61997,     0.62138,     0.62279,      0.6242,     0.63943,     0.64222,     0.64501,      0.6478,     0.65059,     0.66907,      0.6753,     0.68154,     0.70529,     0.73485,     0.74178,      0.7487,     0.75362,     0.75807,     0.76252,     0.76697,     0.77001,     0.77158,     0.77315,\n",
       "            0.77473,      0.7763,     0.77788,     0.77945,     0.78102,      0.7826,     0.78417,     0.78575,     0.78732,     0.78889,     0.79062,     0.79244,     0.79427,     0.79609,     0.79791,     0.79973,     0.80155,     0.80337,      0.8052,     0.80702,     0.80884,     0.81066,     0.81057,\n",
       "             0.8103,     0.81004,     0.80977,     0.80951,     0.80924,     0.80898,     0.80871,     0.80845,     0.80819,     0.80792,     0.80766,     0.80739,     0.80713,     0.80686,      0.8066,     0.80633,     0.80607,      0.8058,     0.80569,     0.80779,     0.80989,     0.81199,     0.81408,\n",
       "            0.81618,     0.81828,     0.82037,     0.82247,     0.82457,     0.82667,     0.82826,     0.82488,     0.82341,     0.82321,     0.82302,     0.82282,     0.82262,     0.82242,     0.82222,     0.82203,     0.82183,     0.82163,     0.82143,     0.82124,     0.82104,     0.82084,     0.82064,\n",
       "            0.82045,     0.82025,     0.82005,     0.81985,     0.81965,     0.81946,     0.81926,     0.81906,     0.81886,     0.81867,     0.81847,     0.81827,     0.81938,     0.82158,     0.82378,     0.82597,     0.82817,     0.83036,     0.83256,     0.83476,     0.83695,     0.83915,     0.84134,\n",
       "            0.84354,     0.84752,     0.85169,     0.85586,     0.86003,      0.8642,     0.86837,     0.87269,     0.87726,     0.88183,      0.8864,     0.89097,     0.89554,     0.90001,     0.90059,     0.90116,     0.90174,     0.90231,     0.90289,     0.90346,     0.90404,     0.90461,     0.90518,\n",
       "            0.90576,     0.90633,     0.90691,     0.90748,     0.90806,     0.90863,     0.90921,     0.90978,     0.91036,     0.91093,     0.91151,     0.91208,     0.91265,     0.91323,      0.9138,     0.91438,     0.91495,     0.91553,      0.9161,     0.91668,     0.91725,     0.91783,      0.9184,\n",
       "            0.91897,     0.91955,     0.92012,      0.9207,     0.92127,     0.92185,     0.92242,       0.923,     0.92357,     0.92415,     0.92472,     0.92529,     0.92587,     0.92644,     0.92702,     0.92759,     0.92817,     0.92874,     0.92932,     0.92989,     0.93047,     0.93104,     0.93121,\n",
       "            0.93139,     0.93157,     0.93174,     0.93192,      0.9321,     0.93228,     0.93245,     0.93263,     0.93281,     0.93298,     0.93316,     0.93334,     0.93351,     0.93369,     0.93387,     0.93405,     0.93422,      0.9344,     0.93458,     0.93475,     0.93493,     0.93511,     0.93528,\n",
       "            0.93546,     0.93564,     0.93582,     0.93599,     0.93617,     0.93635,     0.93652,      0.9367,     0.93688,     0.93705,     0.93723,     0.93741,     0.93759,     0.93776,     0.93794,     0.93812,     0.93829,     0.93847,     0.93865,     0.93882,       0.939,     0.93918,     0.93936,\n",
       "            0.93953,     0.93971,     0.93989,     0.94006,     0.94024,     0.94042,     0.94059,     0.94077,     0.94095,     0.94113,      0.9413,     0.94148,     0.94166,     0.94183,     0.94201,     0.94219,     0.94236,     0.94254,     0.94272,      0.9429,     0.94307,     0.94325,     0.94343,\n",
       "             0.9436,     0.94378,     0.94396,     0.94413,     0.94431,     0.94449,     0.94467,     0.94484,     0.94502,      0.9452,     0.94537,     0.94555,     0.94573,      0.9459,     0.94608,     0.94626,     0.94644,     0.94661,     0.94679,     0.94697,     0.94714,     0.94732,      0.9475,\n",
       "            0.94768,     0.94785,     0.94803,     0.94821,     0.94838,     0.94856,     0.94874,     0.94891,     0.94909,     0.94927,     0.94945,     0.94962,      0.9498,     0.94998,     0.95015,     0.95033,     0.95051,     0.95068,     0.95086,     0.95104,     0.95122,     0.95139,     0.95157,\n",
       "            0.95175,     0.95192,      0.9521,     0.95228,     0.95245,     0.95263,     0.95281,     0.95299,     0.95316,     0.95334,     0.95352,     0.95369,     0.95387,     0.95405,     0.95422,      0.9544,     0.95458,     0.95476,     0.95493,     0.95511,     0.95529,     0.95546,     0.95564,\n",
       "            0.95582,     0.95599,     0.95617,     0.95635,     0.95653,      0.9567,     0.95688,     0.95706,     0.95723,     0.95741,     0.95759,     0.95776,     0.95794,     0.95812,      0.9583,     0.95847,     0.95865,     0.95883,       0.959,     0.95918,     0.95936,     0.95953,     0.95971,\n",
       "            0.95989,     0.96007,     0.96024,     0.96042,      0.9606,     0.96077,     0.96095,     0.96113,      0.9613,     0.96148,     0.96166,     0.96184,     0.96201,     0.96219,     0.96237,     0.96254,     0.96272,      0.9629,     0.96307,     0.96325,     0.96343,     0.96361,     0.96378,\n",
       "            0.96396,     0.96414,     0.96418,     0.96354,     0.96296,     0.96293,     0.96289,     0.96286,     0.96283,     0.96279,     0.96276,     0.96273,     0.96269,     0.96266,     0.96263,     0.96259,     0.96256,     0.96253,     0.96249,     0.96246,     0.96243,     0.96239,     0.96236,\n",
       "            0.96233,     0.96229,     0.96226,     0.96223,     0.96219,     0.96216,     0.96213,     0.96209,     0.96206,     0.96203,     0.96199,     0.96196,     0.96193,     0.96189,     0.96186,     0.96183,     0.96179,     0.96176,     0.96173,     0.96169,     0.96166,     0.96163,     0.96159,\n",
       "            0.96156,     0.96165,     0.96199,     0.96232,     0.96266,     0.96299,     0.96333,     0.96366,       0.964,     0.96433,     0.96467,       0.965,     0.96534,     0.96568,     0.96601,     0.96635,     0.96668,     0.96702,     0.96735,     0.96769,     0.96802,     0.96836,     0.96869,\n",
       "            0.96903,     0.96936,      0.9697,     0.97004,     0.97037,     0.97071,     0.97104,     0.97138,     0.97171,     0.97205,     0.97238,     0.97272,     0.97305,     0.97339,     0.97372,     0.97406,      0.9744,     0.97473,     0.97507,      0.9754,     0.97574,     0.97607,     0.97641,\n",
       "            0.97674,     0.97708,     0.97741,     0.97775,     0.97808,     0.97842,     0.97876,     0.97909,     0.97943,     0.97976,      0.9801,     0.98043,     0.98077,      0.9811,     0.98144,     0.98177,     0.98211,     0.98245,     0.98278,     0.98312,     0.98345,     0.98379,     0.98412,\n",
       "            0.98446,     0.98479,     0.98513,     0.98546,      0.9858,     0.98613,     0.98647,     0.98681,     0.98714,     0.98748,     0.98781,     0.98815,     0.98848,     0.98882,     0.98915,     0.98949,     0.98982,     0.99016,     0.99049,     0.99083,     0.99117,      0.9915,     0.99184,\n",
       "            0.99217,     0.99251,     0.99284,     0.99318,     0.99351,     0.99385,     0.99418,     0.99452,     0.99485,     0.99519,     0.99553,     0.99586,      0.9962,     0.99653,     0.99687,      0.9972,     0.99754,     0.99787,     0.99821,     0.99854,     0.99888,     0.99921,     0.99955,\n",
       "            0.99989,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,     0.96875,     0.96875,     0.96875,     0.96875,     0.96875,     0.96875,     0.96875,     0.96875,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,\n",
       "             0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,\n",
       "             0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,     0.93606,\n",
       "            0.93448,     0.93291,     0.93133,     0.92976,     0.92818,     0.92661,     0.92504,     0.92346,     0.92189,     0.92031,     0.91874,     0.91717,     0.91559,     0.91402,     0.91244,     0.91087,     0.90929,     0.90772,     0.90625,     0.90625,     0.90625,     0.90625,     0.90625,\n",
       "            0.90625,     0.90625,     0.90625,     0.90625,     0.90625,     0.90625,     0.90434,     0.88337,     0.87431,     0.87315,       0.872,     0.87084,     0.86969,     0.86853,     0.86737,     0.86622,     0.86506,     0.86391,     0.86275,      0.8616,     0.86044,     0.85929,     0.85813,\n",
       "            0.85698,     0.85582,     0.85467,     0.85351,     0.85236,      0.8512,     0.85005,     0.84889,     0.84774,     0.84658,     0.84543,     0.84427,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,\n",
       "            0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,\n",
       "            0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,\n",
       "            0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,\n",
       "            0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,\n",
       "            0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,\n",
       "            0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,\n",
       "            0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,\n",
       "            0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,\n",
       "            0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,\n",
       "            0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,\n",
       "            0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,     0.84375,\n",
       "            0.84375,     0.84375,     0.84135,     0.82614,     0.81242,     0.81169,     0.81096,     0.81023,      0.8095,     0.80877,     0.80804,     0.80731,     0.80658,     0.80585,     0.80512,     0.80439,     0.80366,     0.80293,      0.8022,     0.80146,     0.80073,         0.8,     0.79927,\n",
       "            0.79854,     0.79781,     0.79708,     0.79635,     0.79562,     0.79489,     0.79416,     0.79343,      0.7927,     0.79197,     0.79124,      0.7905,     0.78977,     0.78904,     0.78831,     0.78758,     0.78685,     0.78612,     0.78539,     0.78466,     0.78393,      0.7832,     0.78247,\n",
       "            0.78174,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,\n",
       "            0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,\n",
       "            0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,\n",
       "            0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,\n",
       "            0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,     0.78125,\n",
       "            0.78125,     0.78036,     0.77902,     0.77768,     0.77634,     0.77499,     0.77365,     0.77231,     0.77097,     0.76962,     0.76828,     0.76694,      0.7656,     0.76425,     0.76291,     0.76157,     0.76023,     0.75888,     0.75754,      0.7562,     0.75486,     0.75351,     0.75217,\n",
       "            0.75083,     0.74981,     0.74932,     0.74883,     0.74834,     0.74785,     0.74736,     0.74687,     0.74639,      0.7459,     0.74541,     0.74492,     0.74443,     0.74394,     0.74345,     0.74296,     0.74247,     0.74198,     0.74149,       0.741,     0.74051,     0.74002,     0.73953,\n",
       "            0.73904,     0.73855,     0.73806,     0.73757,     0.73708,     0.73659,      0.7361,     0.73561,     0.73512,     0.73464,     0.73415,     0.73366,     0.73317,     0.73268,     0.73219,      0.7317,     0.73121,     0.73072,     0.73023,     0.72974,     0.72925,     0.72876,     0.72827,\n",
       "            0.72778,     0.72729,      0.7268,     0.72631,     0.72582,     0.72533,     0.72484,     0.72435,     0.72386,     0.72337,     0.72289,      0.7224,     0.72191,     0.72142,     0.72093,     0.72044,     0.71995,     0.71946,     0.71897,     0.70832,     0.68948,     0.67889,     0.66926,\n",
       "            0.65964,     0.65556,      0.6545,     0.65344,     0.65238,     0.65132,     0.65026,      0.6492,     0.64814,     0.64708,     0.64602,     0.64496,      0.6439,     0.64284,     0.64178,     0.64072,     0.63966,      0.6386,     0.63754,     0.63648,     0.63542,     0.63436,      0.6333,\n",
       "            0.63224,     0.63118,     0.63012,     0.62906,     0.62799,     0.62693,     0.62587,     0.62461,     0.62236,     0.62012,     0.61788,     0.61564,     0.61339,     0.61115,     0.60891,     0.60666,     0.60442,     0.60218,     0.59994,     0.59769,     0.59545,     0.59086,     0.57894,\n",
       "            0.56701,     0.56124,     0.55922,      0.5572,     0.55517,     0.55315,     0.55113,     0.54911,     0.54708,     0.54506,     0.54304,     0.54101,     0.53899,     0.53697,     0.53495,     0.53292,     0.53074,     0.52776,     0.52479,     0.52181,     0.51883,     0.51586,     0.51288,\n",
       "            0.50991,     0.50693,     0.50396,     0.50098,     0.49659,      0.4915,     0.48642,     0.48133,     0.47624,     0.47116,     0.45623,     0.43564,      0.4269,     0.41815,     0.40941,     0.40212,     0.39565,     0.38918,     0.38271,     0.37624,     0.37438,     0.37361,     0.37284,\n",
       "            0.37208,     0.37131,     0.37054,     0.36977,     0.36901,     0.36824,     0.36747,      0.3667,     0.36593,     0.36517,      0.3644,     0.36363,     0.36286,      0.3621,     0.36133,     0.36056,     0.35979,     0.35903,     0.35826,     0.35749,     0.35672,     0.35596,     0.35519,\n",
       "            0.35442,     0.35365,     0.35288,     0.35212,     0.35135,     0.35058,     0.34981,     0.34905,     0.34828,     0.34751,     0.34674,     0.34598,     0.34521,     0.34444,     0.34365,     0.34267,     0.34169,     0.34072,     0.33974,     0.33876,     0.33778,      0.3368,     0.33582,\n",
       "            0.33484,     0.33387,     0.33289,     0.33191,     0.33093,     0.32995,     0.32897,       0.328,     0.32702,     0.32604,     0.32506,     0.32408,      0.3231,     0.32212,     0.32115,     0.32017,     0.31919,     0.31821,     0.31723,     0.31625,     0.31527,      0.3143,     0.31332,\n",
       "            0.30889,     0.28698,     0.28039,     0.27923,     0.27807,     0.27691,     0.27575,     0.27459,     0.27342,     0.27226,      0.2711,     0.26994,     0.26878,     0.26762,     0.26646,      0.2653,     0.26413,     0.26297,     0.26181,     0.26065,     0.25949,     0.25833,     0.25717,\n",
       "              0.256,     0.25484,     0.25368,     0.25252,     0.25136,      0.2502,     0.24346,     0.23557,     0.22768,     0.21979,     0.20097,      0.1866,     0.18397,     0.18135,     0.17872,     0.17609,     0.17347,     0.17084,     0.16821,     0.16559,     0.16296,     0.16033,     0.15771,\n",
       "            0.14739,     0.12749,     0.11365,     0.10067,    0.093221,    0.092086,    0.090951,    0.089817,    0.088682,    0.087547,    0.086413,    0.085278,    0.084143,    0.083009,    0.081874,    0.080739,    0.079605,     0.07847,    0.077336,    0.076201,    0.075066,    0.073932,    0.072797,\n",
       "           0.071662,    0.070528,    0.069393,    0.068258,    0.067124,    0.065989,    0.064854,     0.06372,    0.062585,    0.061915,    0.061282,     0.06065,    0.060017,    0.059385,    0.058752,    0.058119,    0.057487,    0.056854,    0.056222,    0.055589,    0.054956,    0.054324,    0.053691,\n",
       "           0.053059,    0.052426,    0.051794,    0.051161,    0.050528,    0.049896,    0.049263,    0.048631,    0.047998,    0.047365,    0.046733,      0.0461,    0.045468,    0.044835,    0.044202,     0.04357,    0.042937,    0.042305,    0.041672,     0.04104,    0.040407,    0.039774,    0.039142,\n",
       "           0.038509,    0.037877,    0.037244,    0.036611,    0.035979,    0.035346,    0.034714,    0.034081,    0.033449,    0.032816,    0.032183,    0.031551,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: 0.5177504774310481\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.47012])\n",
       "names: {0: 'pain'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.9554633232536438, 'metrics/recall(B)': 0.84375, 'metrics/mAP50(B)': 0.9464364227522122, 'metrics/mAP50-95(B)': 0.47011870572869646, 'fitness': 0.5177504774310481}\n",
       "save_dir: WindowsPath('runs/detect/train')\n",
       "speed: {'preprocess': 2.2449890772501626, 'inference': 143.35899353027344, 'loss': 0.0, 'postprocess': 0.4579703013102213}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-30 10:58:06,483 - clearml.Task - INFO - Completed model upload to https://files.clear.ml/YOLOv8/train.cb6241137ffb4569bdf7479dc998be14/models/best.pt\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"yolov8.yaml\").load(\"yolov8n.pt\")\n",
    "model.train(data=r\"C:\\Users\\zanyi\\OneDrive\\Git hub\\Ai\\AI Machine Vision\\Pain\\pain-1\\data.yaml\",epochs=80,imgsz=416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\zanyi\\OneDrive\\Git hub\\Ai\\AI Machine Vision\\Pain\\pain-1\\train\\images\\121_jpg.rf.87be90d1b522a789a120fbc9f91db624.jpg: 416x416 1 pain, 123.9ms\n",
      "Speed: 2.0ms preprocess, 123.9ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'pain'}\n",
       " obb: None\n",
       " orig_img: array([[[189, 199, 206],\n",
       "         [188, 198, 205],\n",
       "         [187, 198, 202],\n",
       "         ...,\n",
       "         [248, 240, 240],\n",
       "         [247, 239, 239],\n",
       "         [246, 238, 238]],\n",
       " \n",
       "        [[190, 200, 207],\n",
       "         [189, 199, 206],\n",
       "         [189, 200, 204],\n",
       "         ...,\n",
       "         [248, 240, 240],\n",
       "         [247, 239, 239],\n",
       "         [246, 238, 238]],\n",
       " \n",
       "        [[193, 204, 208],\n",
       "         [192, 203, 207],\n",
       "         [191, 202, 206],\n",
       "         ...,\n",
       "         [249, 241, 241],\n",
       "         [248, 240, 240],\n",
       "         [247, 239, 239]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[161, 158, 154],\n",
       "         [162, 159, 155],\n",
       "         [165, 162, 158],\n",
       "         ...,\n",
       "         [138, 193, 168],\n",
       "         [136, 193, 168],\n",
       "         [136, 193, 168]],\n",
       " \n",
       "        [[163, 158, 155],\n",
       "         [164, 159, 156],\n",
       "         [166, 161, 158],\n",
       "         ...,\n",
       "         [138, 195, 170],\n",
       "         [139, 196, 171],\n",
       "         [139, 196, 171]],\n",
       " \n",
       "        [[163, 158, 155],\n",
       "         [164, 159, 156],\n",
       "         [167, 162, 159],\n",
       "         ...,\n",
       "         [138, 195, 170],\n",
       "         [139, 196, 171],\n",
       "         [140, 197, 172]]], dtype=uint8)\n",
       " orig_shape: (416, 416)\n",
       " path: 'C:\\\\Users\\\\zanyi\\\\OneDrive\\\\Git hub\\\\Ai\\\\AI Machine Vision\\\\Pain\\\\pain-1\\\\train\\\\images\\\\121_jpg.rf.87be90d1b522a789a120fbc9f91db624.jpg'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict'\n",
       " speed: {'preprocess': 2.036571502685547, 'inference': 123.87466430664062, 'postprocess': 0.0}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(r\"C:\\Users\\zanyi\\OneDrive\\Git hub\\Ai\\AI Machine Vision\\Pain\\runs\\detect\\train\\weights\\best.pt\")\n",
    "model.predict(source = r\"C:\\Users\\zanyi\\OneDrive\\Git hub\\Ai\\AI Machine Vision\\Pain\\pain-1\\train\\images\\121_jpg.rf.87be90d1b522a789a120fbc9f91db624.jpg\",save=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
