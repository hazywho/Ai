{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  no model scale passed. Assuming scale='n'.\n",
      "Transferred 355/355 items from pretrained weights\n",
      "New https://pypi.org/project/ultralytics/8.2.51 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.28  Python-3.10.8 torch-2.3.0+cpu CPU (AMD Ryzen 9 4900HS with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8.yaml, data=C:\\Users\\zanyi\\OneDrive\\Git hub\\Ai\\School Anniversary\\EyeAssist\\faceDetection\\faceDataset\\data.yaml, epochs=60, time=None, patience=100, batch=16, imgsz=416, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train4\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "WARNING  no model scale passed. Assuming scale='n'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLOv8 summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train4', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\zanyi\\OneDrive\\Git hub\\Ai\\School Anniversary\\EyeAssist\\faceDetection\\faceDataset\\train\\labels... 2868 images, 536 backgrounds, 0 corrupt: 100%|██████████| 2868/2868 [00:05<00:00, 479.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\zanyi\\OneDrive\\Git hub\\Ai\\School Anniversary\\EyeAssist\\faceDetection\\faceDataset\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\zanyi\\OneDrive\\Git hub\\Ai\\School Anniversary\\EyeAssist\\faceDetection\\faceDataset\\valid\\labels.cache... 267 images, 50 backgrounds, 0 corrupt: 100%|██████████| 267/267 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train4\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 416 train, 416 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train4\u001b[0m\n",
      "Starting training for 60 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/60         0G      1.628      2.038      1.478          7        416: 100%|██████████| 180/180 [24:15<00:00,  8.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:58<00:00,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.684      0.403      0.486      0.231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/60         0G      1.692      1.697      1.516         20        416: 100%|██████████| 180/180 [18:25<00:00,  6.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:47<00:00,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506       0.66      0.494      0.503      0.198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/60         0G      1.719      1.668       1.55         11        416: 100%|██████████| 180/180 [17:12<00:00,  5.74s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:46<00:00,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.279       0.32      0.249      0.116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/60         0G      1.705      1.608       1.55          8        416: 100%|██████████| 180/180 [17:05<00:00,  5.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:46<00:00,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.699      0.584       0.63      0.283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/60         0G      1.654      1.509      1.502          9        416: 100%|██████████| 180/180 [17:04<00:00,  5.69s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:46<00:00,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506       0.75      0.532       0.64      0.305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/60         0G      1.611      1.442      1.476          5        416: 100%|██████████| 180/180 [17:04<00:00,  5.69s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:47<00:00,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.682      0.631      0.664      0.328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/60         0G       1.59      1.384      1.445         15        416: 100%|██████████| 180/180 [17:14<00:00,  5.75s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:46<00:00,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.686      0.555      0.556      0.246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/60         0G      1.535      1.298      1.428         10        416: 100%|██████████| 180/180 [17:08<00:00,  5.72s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:46<00:00,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.769      0.591      0.693      0.371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/60         0G      1.507      1.264      1.412         63        416: 100%|██████████| 180/180 [17:06<00:00,  5.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:46<00:00,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506       0.83      0.626      0.724      0.385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/60         0G      1.475      1.205      1.372          6        416: 100%|██████████| 180/180 [17:01<00:00,  5.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:46<00:00,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.789      0.648      0.737      0.387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/60         0G      1.468      1.207      1.385          7        416: 100%|██████████| 180/180 [17:00<00:00,  5.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:46<00:00,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.787      0.677      0.756      0.407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/60         0G      1.427       1.17      1.365         12        416: 100%|██████████| 180/180 [16:55<00:00,  5.64s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:45<00:00,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.832      0.692      0.786      0.393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/60         0G      1.425      1.168      1.351         13        416: 100%|██████████| 180/180 [16:53<00:00,  5.63s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:46<00:00,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.833      0.638      0.757      0.394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/60         0G       1.41      1.132      1.337          2        416: 100%|██████████| 180/180 [16:55<00:00,  5.64s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:46<00:00,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.833       0.66      0.751      0.419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/60         0G      1.371      1.083      1.321          4        416: 100%|██████████| 180/180 [17:01<00:00,  5.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:46<00:00,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.825      0.687      0.782      0.439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/60         0G      1.378       1.07      1.322          5        416: 100%|██████████| 180/180 [17:16<00:00,  5.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:47<00:00,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.836      0.711       0.79      0.448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/60         0G       1.35      1.052      1.301         43        416: 100%|██████████| 180/180 [17:26<00:00,  5.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:47<00:00,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.847      0.713      0.797      0.425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/60         0G      1.332      1.023      1.293          9        416: 100%|██████████| 180/180 [17:28<00:00,  5.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:47<00:00,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.874      0.724      0.812      0.453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/60         0G      1.313     0.9975      1.286          7        416: 100%|██████████| 180/180 [17:26<00:00,  5.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:47<00:00,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.838      0.708      0.786      0.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/60         0G      1.293     0.9967      1.272          5        416: 100%|██████████| 180/180 [17:33<00:00,  5.85s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:48<00:00,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.835      0.709      0.796      0.469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/60         0G      1.277     0.9829      1.269         11        416: 100%|██████████| 180/180 [17:32<00:00,  5.85s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:47<00:00,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.835      0.737      0.827      0.471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/60         0G      1.293     0.9647      1.257         39        416:  67%|██████▋   | 120/180 [11:58<08:55,  8.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nvidia driver cannot export utilization, pushing fixed value 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/60         0G      1.288     0.9614       1.26          8        416: 100%|██████████| 180/180 [1:33:04<00:00, 31.03s/it]     \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [01:06<00:00,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.842      0.723      0.821      0.443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/60         0G      1.237     0.9325      1.238         13        416: 100%|██████████| 180/180 [16:29<00:00,  5.50s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:46<00:00,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.851      0.662      0.803      0.468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/60         0G      1.255     0.9248      1.246          4        416: 100%|██████████| 180/180 [17:14<00:00,  5.75s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:47<00:00,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.868      0.731      0.818      0.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/60         0G      1.229     0.9098      1.244          3        416: 100%|██████████| 180/180 [17:22<00:00,  5.79s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:47<00:00,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506       0.84      0.696      0.817      0.463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/60         0G      1.205     0.8794      1.229          5        416: 100%|██████████| 180/180 [17:26<00:00,  5.81s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:47<00:00,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.867      0.746      0.841      0.484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/60         0G      1.221     0.8902      1.224          6        416: 100%|██████████| 180/180 [17:37<00:00,  5.87s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:47<00:00,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.915      0.725      0.836      0.496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/60         0G       1.23     0.8939      1.218         17        416: 100%|██████████| 180/180 [17:44<00:00,  5.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:48<00:00,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.852      0.745      0.824      0.492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/60         0G      1.189     0.8626      1.204          8        416: 100%|██████████| 180/180 [17:32<00:00,  5.85s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:45<00:00,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.882      0.713      0.828      0.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/60         0G      1.193      0.879      1.207          5        416: 100%|██████████| 180/180 [16:42<00:00,  5.57s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:46<00:00,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.888      0.723      0.835      0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/60         0G      1.171     0.8348      1.195          6        416: 100%|██████████| 180/180 [17:08<00:00,  5.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:47<00:00,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.889      0.741      0.833      0.474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/60         0G       1.18      0.831      1.194          8        416: 100%|██████████| 180/180 [17:23<00:00,  5.80s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:47<00:00,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.882      0.709      0.823      0.493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/60         0G      1.143     0.8112      1.177         11        416: 100%|██████████| 180/180 [17:31<00:00,  5.84s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:48<00:00,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506        0.9      0.746      0.858        0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/60         0G       1.13     0.7895      1.181         12        416: 100%|██████████| 180/180 [17:43<00:00,  5.91s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:49<00:00,  5.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.878      0.717      0.813      0.491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/60         0G      1.116     0.7679      1.165          7        416: 100%|██████████| 180/180 [17:53<00:00,  5.96s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:49<00:00,  5.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.894      0.753      0.848      0.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/60         0G      1.103     0.7687      1.163         12        416: 100%|██████████| 180/180 [18:03<00:00,  6.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:49<00:00,  5.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.875      0.749      0.843      0.502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/60         0G      1.126     0.7739       1.17          8        416: 100%|██████████| 180/180 [17:48<00:00,  5.94s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:46<00:00,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.847      0.765      0.834      0.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/60         0G      1.082     0.7537      1.145         37        416:  42%|████▏     | 75/180 [2:16:15<67:58:04, 2330.33s/it]Retrying (Retry(total=237, connect=238, read=239, redirect=240, status=240)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001D385A099F0>: Failed to resolve 'api.clear.ml' ([Errno 11001] getaddrinfo failed)\")': /v2.23/events.add_batch\n",
      "Retrying (Retry(total=237, connect=237, read=240, redirect=240, status=240)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001D385A0A4D0>: Failed to resolve 'api.clear.ml' ([Errno 11001] getaddrinfo failed)\")': /v2.23/tasks.get_all\n",
      "Retrying (Retry(total=237, connect=237, read=240, redirect=240, status=240)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001D385A09B40>: Failed to resolve 'api.clear.ml' ([Errno 11001] getaddrinfo failed)\")': /v2.23/tasks.get_all\n",
      "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m Heartbeat processing error\n",
      "Retrying (Retry(total=236, connect=237, read=239, redirect=240, status=240)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001D3EC0D5900>: Failed to resolve 'api.clear.ml' ([Errno 11001] getaddrinfo failed)\")': /v2.23/events.add_batch\n",
      "Retrying (Retry(total=236, connect=236, read=240, redirect=240, status=240)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001D3EC0D50F0>: Failed to resolve 'api.clear.ml' ([Errno 11001] getaddrinfo failed)\")': /v2.23/tasks.get_all\n",
      "      38/60         0G      1.081     0.7533      1.144         62        416:  42%|████▏     | 76/180 [2:16:24<47:11:50, 1633.75s/it]Retrying (Retry(total=236, connect=236, read=240, redirect=240, status=240)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001D3EC0D5330>: Failed to resolve 'api.clear.ml' ([Errno 11001] getaddrinfo failed)\")': /v2.23/tasks.get_all\n",
      "      38/60         0G      1.092     0.7623      1.148         29        416:  46%|████▌     | 83/180 [2:17:01<3:45:11, 139.29s/it]  Retrying (Retry(total=235, connect=236, read=239, redirect=240, status=240)) after connection broken by 'ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001D3EC0D5450>, 'Connection to api.clear.ml timed out. (connect timeout=10.0)')': /v2.23/events.add_batch\n",
      "Retrying (Retry(total=235, connect=235, read=240, redirect=240, status=240)) after connection broken by 'ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001D3EC0D68C0>, 'Connection to api.clear.ml timed out. (connect timeout=10.0)')': /v2.23/tasks.get_all\n",
      "Retrying (Retry(total=235, connect=235, read=240, redirect=240, status=240)) after connection broken by 'ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001D3F408D630>, 'Connection to api.clear.ml timed out. (connect timeout=10.0)')': /v2.23/tasks.get_all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-09 14:54:00,192 - clearml.Task - WARNING - ### TASK STOPPED - USER ABORTED - STATUS CHANGED ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/60         0G      1.092     0.7619      1.147         35        416:  47%|████▋     | 84/180 [2:17:07<2:38:47, 99.25s/it] "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"yolov8.yaml\").load(\"yolov8n.pt\")\n",
    "model.train(data=r\"C:\\Users\\zanyi\\OneDrive\\Git hub\\Ai\\School Anniversary\\EyeAssist\\faceDetection\\faceDataset\\data.yaml\",epochs=60,imgsz=416)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.51 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.28  Python-3.10.8 torch-2.3.0+cpu CPU (AMD Ryzen 9 4900HS with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=C:\\Users\\zanyi\\OneDrive\\Git hub\\Ai\\School Anniversary\\EyeAssist\\faceDetection\\runs\\detect\\train4\\weights\\last.pt, data=C:\\Users\\zanyi\\OneDrive\\Git hub\\Ai\\School Anniversary\\EyeAssist\\faceDetection\\faceDataset\\data.yaml, epochs=60, time=None, patience=100, batch=16, imgsz=416, save=True, save_period=-1, cache=False, device=None, workers=0, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=C:\\Users\\zanyi\\OneDrive\\Git hub\\Ai\\School Anniversary\\EyeAssist\\faceDetection\\runs\\detect\\train4\\weights\\last.pt, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train4\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train4', view at http://localhost:6006/\n",
      "WARNING  no model scale passed. Assuming scale='n'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLOv8 summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\zanyi\\OneDrive\\Git hub\\Ai\\School Anniversary\\EyeAssist\\faceDetection\\faceDataset\\train\\labels.cache... 2868 images, 536 backgrounds, 0 corrupt: 100%|██████████| 2868/2868 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\zanyi\\OneDrive\\Git hub\\Ai\\School Anniversary\\EyeAssist\\faceDetection\\faceDataset\\valid\\labels.cache... 267 images, 50 backgrounds, 0 corrupt: 100%|██████████| 267/267 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train4\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Resuming training C:\\Users\\zanyi\\OneDrive\\Git hub\\Ai\\School Anniversary\\EyeAssist\\faceDetection\\runs\\detect\\train4\\weights\\last.pt from epoch 48 to 60 total epochs\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 416 train, 416 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train4\u001b[0m\n",
      "Starting training for 60 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/60         0G      1.027     0.6714      1.108          7        416: 100%|██████████| 180/180 [22:35<00:00,  7.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:57<00:00,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.888      0.734      0.841      0.511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/60         0G       1.01     0.6604      1.102         20        416: 100%|██████████| 180/180 [20:22<00:00,  6.79s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:51<00:00,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.909       0.75      0.861      0.526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/60         0G      1.019     0.6598      1.109         11        416: 100%|██████████| 180/180 [19:23<00:00,  6.46s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:50<00:00,  5.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.886      0.755      0.849      0.529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      51/60         0G     0.9299     0.5662      1.056          3        416: 100%|██████████| 180/180 [18:49<00:00,  6.27s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:50<00:00,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.912      0.739      0.858      0.531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      52/60         0G     0.8978     0.5375      1.037          3        416: 100%|██████████| 180/180 [18:44<00:00,  6.24s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:50<00:00,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.912      0.745      0.858      0.526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      53/60         0G     0.8964     0.5349      1.027          5        416: 100%|██████████| 180/180 [18:38<00:00,  6.21s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:50<00:00,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.872      0.779      0.869      0.538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      54/60         0G     0.8779     0.5186      1.022          2        416: 100%|██████████| 180/180 [18:45<00:00,  6.26s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:50<00:00,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.881      0.775      0.863      0.529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      55/60         0G     0.8784     0.5118      1.019          4        416: 100%|██████████| 180/180 [18:42<00:00,  6.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:50<00:00,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.879      0.775       0.86      0.535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      56/60         0G     0.8545     0.5053      1.007          4        416: 100%|██████████| 180/180 [18:39<00:00,  6.22s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:50<00:00,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.915      0.748      0.857      0.535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      57/60         0G     0.8499     0.4975      1.009          2        416: 100%|██████████| 180/180 [18:39<00:00,  6.22s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:50<00:00,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.881      0.774      0.857      0.535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      58/60         0G      0.839     0.4907     0.9964          7        416: 100%|██████████| 180/180 [18:35<00:00,  6.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:50<00:00,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506       0.91      0.743      0.858      0.539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      59/60         0G     0.8219     0.4793     0.9909          5        416: 100%|██████████| 180/180 [18:40<00:00,  6.22s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:50<00:00,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.897      0.773      0.864      0.539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      60/60         0G     0.8222     0.4861     0.9901          1        416: 100%|██████████| 180/180 [18:32<00:00,  6.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:49<00:00,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.897      0.775      0.866       0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "13 epochs completed in 4.344 hours.\n",
      "Optimizer stripped from runs\\detect\\train4\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train4\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train4\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.28  Python-3.10.8 torch-2.3.0+cpu CPU (AMD Ryzen 9 4900HS with Radeon Graphics)\n",
      "YOLOv8 summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:44<00:00,  4.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267        506      0.897      0.775      0.867      0.539\n",
      "Speed: 2.8ms preprocess, 148.6ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train4\u001b[0m\n",
      "2024-07-10 03:47:39,997 - clearml.storage - INFO - Starting upload: runs\\detect\\train4\\weights\\best.pt => https://files.clear.ml/YOLOv8/train4.2074b985d5d74291aeb9a8c2e7c6d75f/models/best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/hazywho/general/a403891bcb674abe9348ea6e7fe8cf9d\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [31]               : (5.30000000000001e-05, 0.000515)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [31]               : (5.30000000000001e-05, 0.000515)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [31]               : (5.30000000000001e-05, 0.000515)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B) [32]     : (0.84095, 0.86907)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [32]  : (0.51096, 0.53953)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [32] : (0.87239, 0.91537)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B) [32]    : (0.73364, 0.77866)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [30]       : (0.82194, 1.02666)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [30]       : (0.4793, 0.67143)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [30]       : (0.99005, 1.10877)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [30]         : (1.11284, 1.17779)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [30]         : (0.58901, 0.64962)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [30]         : (1.14162, 1.21376)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : C:\\Users\\zanyi\\OneDrive\\Git hub\\Ai\\School Anniversary\\EyeAssist\\faceDetection\\faceDataset\\data.yaml\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 60\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 416\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     label_smoothing : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : C:\\Users\\zanyi\\OneDrive\\Git hub\\Ai\\School Anniversary\\EyeAssist\\faceDetection\\runs\\detect\\train4\\weights\\last.pt\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : C:\\Users\\zanyi\\OneDrive\\Git hub\\Ai\\School Anniversary\\EyeAssist\\faceDetection\\runs\\detect\\train4\\weights\\last.pt\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs\\detect\\train4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : detect\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed) : 1 (13.77 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images                   : 7\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element            : 1 (5.93 MB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 2 file(s), remaining 5.59 MB/6.82 MB\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 2.40 MB/6.82 MB, Throughput 215.35 KB/s, ETA ~12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001F993DF9120>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,\n",
       "             0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,\n",
       "             0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,      0.9959,       0.992,       0.992,       0.992,\n",
       "              0.992,       0.992,       0.992,       0.992,       0.992,       0.992,       0.992,     0.98814,     0.98814,     0.98814,     0.98814,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,\n",
       "            0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,\n",
       "            0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98333,     0.98333,     0.98333,\n",
       "            0.98333,     0.98333,     0.98333,     0.98333,     0.98333,     0.98333,     0.98333,     0.98333,     0.98333,     0.98333,     0.98333,     0.98333,     0.98333,     0.98333,     0.98333,     0.98333,     0.98333,     0.98333,     0.98333,     0.98333,     0.98333,     0.98333,     0.98333,\n",
       "            0.98333,     0.98333,     0.98333,     0.98333,     0.98333,     0.98333,     0.98333,     0.98333,     0.98101,     0.98101,     0.98101,     0.98101,     0.98101,     0.98101,     0.98101,     0.98101,     0.98101,     0.98101,     0.98101,     0.98101,     0.98101,     0.98101,     0.98101,\n",
       "            0.98101,     0.98101,     0.98101,     0.98101,     0.98101,     0.98101,     0.98101,     0.98101,     0.98101,     0.98101,     0.98101,     0.98101,     0.98101,     0.98101,     0.98101,     0.96904,     0.96904,     0.96904,     0.96904,     0.96904,     0.96626,     0.96626,     0.96626,\n",
       "            0.96626,     0.96501,     0.96501,     0.96501,     0.96501,     0.96501,     0.96501,     0.96501,     0.96501,     0.96501,     0.96501,     0.96501,     0.96501,     0.96501,     0.96501,     0.96501,     0.96501,     0.96501,     0.96501,     0.96501,     0.96501,     0.96501,     0.96501,\n",
       "            0.96501,     0.96501,     0.96501,     0.96501,     0.96501,     0.96501,     0.96501,     0.96501,     0.96501,     0.96501,     0.96254,     0.96254,     0.96254,     0.96254,     0.96254,     0.96254,     0.95775,     0.95775,     0.95775,     0.95775,     0.95775,     0.95775,     0.95775,\n",
       "            0.95775,     0.95775,     0.95775,     0.95775,     0.95775,     0.95543,     0.95543,     0.95543,     0.95543,     0.95543,     0.95543,     0.95317,     0.95317,     0.95317,     0.95317,     0.95317,     0.95317,     0.95095,     0.95095,     0.95095,     0.95095,     0.95095,     0.95095,\n",
       "            0.94865,     0.94865,     0.94865,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94503,     0.94503,\n",
       "            0.94301,     0.94301,     0.94301,     0.94301,     0.94301,     0.94301,     0.93846,     0.93846,     0.93846,     0.93846,     0.93384,     0.93384,     0.93165,     0.93165,     0.92947,     0.92947,     0.92732,     0.92732,      0.9206,      0.9206,     0.91892,     0.91892,     0.91892,\n",
       "            0.91892,     0.91892,     0.91892,     0.91768,     0.91768,     0.91768,     0.91768,     0.91768,     0.91768,     0.91768,     0.91768,     0.91768,     0.91768,     0.91566,     0.91566,     0.90974,     0.90974,     0.90974,     0.90974,     0.90974,     0.90974,      0.9078,      0.9078,\n",
       "            0.90588,     0.90588,     0.90255,     0.90255,     0.90255,     0.90255,     0.90255,     0.90255,     0.90255,     0.90255,     0.90069,     0.89908,     0.89908,     0.89908,     0.89908,     0.89726,     0.89726,     0.88739,     0.88739,     0.87973,     0.87973,     0.87805,     0.87805,\n",
       "            0.87445,     0.87445,       0.869,       0.869,     0.86768,     0.86768,     0.86768,     0.86768,     0.86237,     0.86237,     0.86081,     0.86081,     0.85928,     0.85928,     0.85084,     0.85084,     0.85084,     0.85084,     0.84407,     0.84407,     0.82389,     0.82389,     0.81764,\n",
       "            0.81764,     0.81386,     0.81386,     0.81386,     0.81386,     0.81386,     0.81386,     0.79845,     0.79845,     0.79769,     0.79769,     0.79769,     0.79769,      0.7845,      0.7845,     0.77467,     0.77467,     0.77365,     0.77365,     0.76838,     0.76838,     0.74955,     0.74955,\n",
       "            0.73345,     0.73345,     0.73345,     0.73345,     0.72633,     0.72633,     0.72061,     0.72061,     0.71261,     0.71261,     0.70481,     0.70481,     0.68982,     0.68982,     0.68982,     0.68982,      0.6875,      0.6875,      0.6875,     0.68521,     0.68521,     0.68521,     0.68521,\n",
       "              0.675,       0.675,     0.66821,     0.66821,     0.65809,     0.65809,     0.65809,     0.65809,     0.65663,     0.65663,     0.64933,     0.64933,     0.64602,     0.64602,     0.61918,     0.61918,     0.61625,     0.61625,     0.61335,     0.61335,     0.61304,     0.61304,     0.61019,\n",
       "            0.61019,      0.6049,      0.6049,     0.58399,     0.58399,     0.57772,     0.57772,      0.5687,      0.5687,     0.56781,     0.56781,     0.55432,     0.55432,     0.55283,     0.55283,       0.546,       0.546,         0.5,         0.5,     0.49508,     0.49508,     0.48504,     0.48504,\n",
       "            0.46099,     0.46099,     0.45328,     0.45328,     0.41171,     0.41171,     0.39654,     0.39654,     0.38526,     0.38526,     0.38526,     0.38526,     0.35326,     0.35326,     0.33142,     0.33142,     0.31803,     0.31803,     0.31803,     0.31803,     0.26786,     0.26786,     0.26004,\n",
       "            0.26004,     0.24605,     0.24605,      0.2138,     0.20817,     0.20817,     0.20302,     0.20302,     0.19924,     0.19924,     0.18359,     0.18359,     0.17551,     0.17551,     0.16803,     0.16803,     0.12616,     0.12616,     0.11261,     0.11261,     0.10467,     0.10467,    0.096859,\n",
       "           0.096859,    0.083917,    0.083917,    0.080515,    0.078996,    0.077477,    0.075958,    0.074439,    0.072919,      0.0714,    0.069881,    0.068362,    0.066843,    0.065324,    0.063805,    0.062285,    0.060766,    0.059247,    0.057728,    0.056209,     0.05469,     0.05317,    0.051651,\n",
       "           0.050132,    0.048613,    0.047094,    0.045575,    0.044055,    0.042536,    0.041017,    0.039498,    0.037979,     0.03646,    0.034941,    0.033421,    0.031902,    0.030383,    0.028864,    0.027345,    0.025826,    0.024306,    0.022787,    0.021268,    0.019749,     0.01823,    0.016711,\n",
       "           0.015192,    0.013672,    0.012153,    0.010634,   0.0091149,   0.0075958,   0.0060766,   0.0045575,   0.0030383,   0.0015192,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[     0.1492,     0.14925,     0.19732,     0.22695,     0.24968,     0.27172,     0.28858,     0.30431,     0.31971,     0.33341,      0.3467,      0.3592,     0.37185,     0.38219,     0.38998,     0.40174,     0.41048,     0.41892,     0.42847,     0.43461,     0.44255,     0.45149,     0.46002,\n",
       "            0.47029,     0.47682,     0.48323,     0.49072,     0.49887,     0.50423,     0.51002,     0.51505,     0.52035,     0.52558,     0.53068,     0.53703,     0.54058,     0.54396,     0.54854,     0.55271,     0.55469,     0.55906,     0.56346,     0.56746,     0.57141,     0.57566,     0.57927,\n",
       "            0.58222,     0.58566,     0.58901,     0.59113,     0.59326,      0.5977,     0.60094,     0.60229,     0.60508,     0.60931,     0.61028,     0.61238,     0.61641,     0.61953,     0.62364,      0.6252,      0.6291,     0.62955,     0.63246,     0.63475,     0.64103,     0.64192,     0.64585,\n",
       "            0.64837,     0.65032,     0.65238,     0.65486,     0.65722,     0.65913,     0.66304,      0.6667,     0.66927,     0.67314,      0.6753,     0.67785,     0.67839,     0.67914,     0.68127,      0.6829,     0.68742,     0.68859,     0.69081,     0.69184,     0.69228,     0.69308,     0.69443,\n",
       "            0.69607,     0.69789,     0.69848,     0.70012,     0.70174,     0.70338,     0.70613,     0.70693,     0.70983,      0.7113,     0.71321,      0.7158,      0.7151,      0.7156,     0.71716,     0.71855,     0.71848,     0.71959,     0.71911,     0.71967,     0.72052,     0.72058,     0.72179,\n",
       "            0.72271,     0.72592,     0.72656,     0.72802,     0.72864,     0.72945,     0.72986,     0.73106,     0.73363,     0.73692,     0.73742,     0.73831,     0.73951,     0.73938,     0.73932,     0.74019,     0.74126,     0.74147,     0.74229,     0.74387,     0.74525,     0.74424,     0.74486,\n",
       "            0.74403,     0.74441,     0.74529,      0.7474,     0.74967,     0.75117,     0.75174,     0.75244,     0.75347,     0.75356,      0.7544,     0.75553,      0.7563,      0.7567,     0.75704,     0.75735,     0.75886,     0.75891,     0.75879,     0.75763,     0.75733,     0.75767,      0.7584,\n",
       "            0.75883,     0.75692,     0.75794,     0.75937,     0.75981,     0.76011,     0.76136,     0.76344,     0.76402,     0.76508,     0.76557,     0.76595,     0.76625,      0.7663,     0.76583,     0.76536,     0.76832,     0.76874,     0.76998,     0.76919,      0.7694,     0.76975,     0.77051,\n",
       "            0.77079,     0.77108,     0.77211,     0.77251,     0.77377,     0.77312,     0.77332,     0.77439,     0.77586,     0.77581,     0.77892,     0.77914,     0.77935,     0.77957,     0.77739,     0.77797,     0.77843,     0.77919,     0.77985,     0.78022,     0.78216,     0.78283,      0.7833,\n",
       "            0.78368,     0.78411,     0.78462,     0.78653,     0.78628,     0.78611,     0.78734,     0.78799,     0.78824,     0.78848,     0.78882,     0.78949,     0.78999,     0.79037,     0.79068,     0.79097,      0.7912,     0.79143,     0.79165,     0.79347,     0.79574,     0.79566,     0.79514,\n",
       "            0.79554,     0.79591,     0.79625,     0.79666,     0.79777,     0.79698,     0.79726,     0.79657,     0.79669,     0.79681,     0.79693,     0.79705,     0.79716,     0.79728,      0.7975,     0.79776,     0.79802,     0.79846,     0.79963,     0.80004,     0.80046,     0.80096,     0.80163,\n",
       "            0.80089,     0.80143,      0.8026,     0.80351,     0.80522,     0.80561,     0.80584,     0.80607,     0.80627,     0.80641,     0.80654,     0.80668,     0.80682,     0.80695,     0.80746,     0.80551,     0.80584,     0.80618,      0.8055,     0.80534,     0.80575,     0.80609,      0.8064,\n",
       "            0.80738,     0.80937,     0.80988,     0.81084,     0.81154,     0.81185,     0.81216,      0.8126,     0.81188,     0.81116,     0.81029,     0.81053,      0.8112,     0.81166,     0.81079,     0.81092,     0.81105,     0.81118,     0.81131,     0.81144,     0.81181,     0.81266,     0.81301,\n",
       "            0.81338,     0.81378,     0.81374,     0.81319,     0.81292,     0.81324,     0.81357,     0.81378,     0.81398,     0.81417,     0.81436,     0.81456,     0.81475,     0.81495,     0.81515,     0.81612,      0.8166,     0.81718,     0.81857,     0.81884,     0.81912,     0.81942,     0.82014,\n",
       "            0.82118,     0.82144,     0.82171,       0.822,     0.82232,     0.82265,     0.82182,     0.82183,     0.82231,     0.82346,     0.82378,     0.82441,     0.82459,     0.82421,     0.82383,     0.82331,      0.8235,     0.82369,     0.82388,     0.82407,      0.8251,     0.82543,     0.82576,\n",
       "            0.82596,     0.82613,      0.8263,     0.82647,     0.82664,      0.8255,     0.82564,     0.82577,      0.8259,     0.82603,     0.82617,      0.8263,     0.82566,     0.82576,     0.82562,     0.82526,      0.8249,     0.82504,     0.82558,     0.82658,     0.82674,      0.8269,     0.82706,\n",
       "            0.82722,     0.82527,     0.82495,     0.82504,     0.82512,     0.82521,      0.8253,     0.82539,     0.82547,     0.82556,     0.82565,     0.82538,     0.82481,     0.82524,     0.82583,     0.82633,      0.8266,     0.82687,     0.82627,     0.82599,     0.82613,     0.82628,     0.82642,\n",
       "            0.82657,     0.82671,     0.82692,     0.82713,     0.82734,     0.82755,     0.82656,     0.82602,     0.82632,     0.82662,     0.82749,     0.82873,     0.82895,     0.82918,      0.8294,      0.8283,     0.82848,     0.82866,     0.82884,     0.82902,     0.82922,     0.82944,     0.82966,\n",
       "            0.82989,     0.83008,     0.83024,      0.8304,     0.83056,     0.83072,     0.83087,     0.83094,     0.83101,     0.83108,     0.83115,     0.83121,     0.83128,     0.83135,     0.83142,     0.83149,     0.83156,     0.83163,      0.8317,      0.8319,     0.83248,     0.83246,     0.83223,\n",
       "            0.83199,     0.83176,     0.83153,     0.83144,     0.83159,     0.83174,     0.83189,     0.83203,     0.83218,     0.83133,     0.83069,     0.83031,     0.82993,     0.83006,     0.82947,     0.82956,     0.82966,     0.82975,     0.82984,     0.82994,     0.83003,     0.83013,     0.83022,\n",
       "             0.8303,     0.83004,     0.82978,     0.82952,     0.82926,     0.82897,      0.8286,     0.82822,     0.82785,     0.82755,     0.82726,     0.82697,     0.82668,     0.82546,      0.8263,     0.82645,     0.82661,     0.82677,     0.82692,     0.82702,     0.82644,     0.82585,     0.82603,\n",
       "            0.82626,      0.8265,     0.82668,     0.82657,     0.82647,     0.82636,     0.82626,     0.82615,     0.82605,     0.82595,     0.82584,     0.82574,     0.82563,     0.82553,     0.82544,     0.82566,     0.82588,      0.8261,     0.82631,     0.82437,     0.82358,     0.82325,     0.82291,\n",
       "            0.82257,       0.823,     0.82343,     0.82351,     0.82358,     0.82366,     0.82374,     0.82382,      0.8239,     0.82398,     0.82405,     0.82413,     0.82421,     0.82429,     0.82446,     0.82463,      0.8248,     0.82497,     0.82515,     0.82508,     0.82493,     0.82479,     0.82464,\n",
       "            0.82449,     0.82434,     0.82419,     0.82405,     0.82393,     0.82408,     0.82423,     0.82438,     0.82453,     0.82468,     0.82475,     0.82429,     0.82382,     0.82314,     0.82208,     0.82096,     0.82085,     0.82075,     0.82064,     0.82054,     0.82043,     0.82033,     0.82022,\n",
       "            0.82012,     0.82001,      0.8199,      0.8198,     0.81969,     0.81958,     0.81946,     0.81934,     0.81922,     0.81911,     0.81899,     0.81887,     0.81875,     0.81863,     0.81852,      0.8184,     0.81859,     0.81884,     0.81909,     0.81893,     0.81743,     0.81657,     0.81635,\n",
       "            0.81614,     0.81593,     0.81572,      0.8155,     0.81554,     0.81588,     0.81621,     0.81514,     0.81541,     0.81568,     0.81598,     0.81636,     0.81673,     0.81736,     0.81697,     0.81657,     0.81709,     0.81668,     0.81626,     0.81603,     0.81629,     0.81654,     0.81679,\n",
       "            0.81662,     0.81626,     0.81589,     0.81557,     0.81573,     0.81589,     0.81604,      0.8162,     0.81636,     0.81629,     0.81583,     0.81537,     0.81563,     0.81691,     0.81669,     0.81641,     0.81613,     0.81585,     0.81548,     0.81482,     0.81498,     0.81574,     0.81595,\n",
       "            0.81528,     0.81468,     0.81423,     0.81379,     0.81301,     0.81227,     0.81255,     0.81282,     0.81304,     0.81287,      0.8127,     0.81253,     0.81236,     0.81219,     0.81203,     0.81186,     0.81182,     0.81228,     0.81235,     0.81034,      0.8098,     0.80963,     0.80946,\n",
       "            0.80929,     0.80911,     0.80894,     0.80877,     0.80847,     0.80709,     0.80666,     0.80622,     0.80576,     0.80524,     0.80472,     0.80415,     0.80355,     0.80307,     0.80276,     0.80245,     0.80215,     0.80184,     0.80146,     0.80107,     0.80068,     0.80042,     0.79923,\n",
       "            0.79902,     0.79817,     0.79713,     0.79565,     0.79567,     0.79597,     0.79628,     0.79424,      0.7929,     0.79239,     0.79283,     0.79133,     0.79031,     0.78948,     0.78972,     0.78899,     0.78794,     0.78547,     0.78511,     0.78475,     0.78438,     0.78352,     0.78221,\n",
       "            0.78138,     0.78306,     0.78218,     0.77888,     0.77902,     0.77916,      0.7793,     0.77944,     0.77958,     0.77972,     0.77831,     0.77536,     0.77431,     0.77363,     0.77312,     0.77262,     0.77163,     0.77003,     0.76666,     0.76636,     0.76606,     0.76576,     0.76546,\n",
       "            0.76509,     0.76422,     0.76282,     0.76077,     0.75987,     0.75784,     0.75698,     0.75646,     0.75686,     0.75484,     0.75351,     0.75279,     0.75198,     0.75169,     0.75253,     0.75401,     0.74944,     0.74762,     0.74613,     0.74039,     0.73931,     0.73714,     0.73642,\n",
       "            0.73561,     0.73436,      0.7332,      0.7317,     0.73138,      0.7318,      0.7308,     0.72968,     0.72843,     0.72653,     0.72479,     0.72085,     0.71976,     0.71725,     0.71449,     0.71134,     0.70926,     0.70881,     0.70836,     0.70717,     0.70295,     0.70018,     0.69952,\n",
       "            0.69872,     0.69737,     0.69607,     0.69461,     0.69293,     0.69128,     0.68918,      0.6867,     0.68328,       0.681,       0.678,     0.67331,     0.67195,     0.67003,     0.66865,      0.6613,     0.66057,     0.65984,     0.65867,      0.6584,     0.65779,     0.65553,     0.65539,\n",
       "            0.65405,     0.65353,     0.65302,     0.65236,     0.64945,     0.64307,     0.63964,     0.63848,     0.63776,     0.63679,     0.63317,     0.63246,     0.63174,     0.62856,     0.62631,     0.62084,     0.61907,     0.61607,     0.61085,     0.60954,     0.60853,     0.60771,     0.60581,\n",
       "            0.60115,     0.60002,     0.59814,     0.59541,     0.59477,     0.59414,     0.59349,     0.59274,       0.592,     0.58991,     0.58693,     0.58189,      0.5801,     0.57801,       0.577,     0.57223,     0.57043,     0.56911,     0.56557,     0.56116,     0.55692,     0.55512,     0.55081,\n",
       "            0.54786,      0.5463,     0.54127,     0.53998,     0.53859,      0.5373,     0.53636,     0.53538,     0.53388,     0.53254,     0.53128,     0.52815,     0.52615,     0.52428,     0.52215,     0.52145,     0.52074,     0.51904,     0.51665,     0.51448,     0.51249,      0.5076,     0.50593,\n",
       "            0.50456,     0.50335,     0.49849,     0.49639,     0.49159,     0.48999,     0.48662,      0.4822,     0.48131,     0.48029,     0.47701,     0.47253,     0.46949,     0.46417,     0.46312,     0.46208,     0.45822,     0.45344,      0.4464,     0.44241,     0.44147,     0.43961,     0.43013,\n",
       "            0.42676,     0.42273,     0.41627,      0.4154,     0.41453,     0.41198,     0.40841,     0.40197,     0.39936,     0.39314,       0.389,     0.38354,     0.38014,     0.37204,     0.36608,     0.35412,     0.35066,     0.34115,     0.32127,     0.31919,     0.31281,     0.30803,     0.29228,\n",
       "             0.2885,     0.28492,     0.27253,     0.26643,     0.26203,     0.25687,     0.24666,     0.23989,      0.2319,     0.22495,     0.20787,     0.20112,      0.1956,     0.19343,      0.1889,     0.16745,     0.15759,     0.14607,     0.12603,     0.11929,     0.11087,     0.10452,    0.097142,\n",
       "           0.084978,    0.075877,    0.073301,    0.065838,     0.06138,    0.053483,    0.050188,      0.0483,     0.04645,    0.038076,     0.03471,    0.032744,    0.030478,    0.026715,    0.019658,    0.015507,    0.014795,    0.014082,    0.013369,    0.012655,    0.011941,    0.008123,   0.0068486,\n",
       "          0.0057644,   0.0046789,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.080981,    0.081011,     0.11022,     0.12911,     0.14403,     0.15891,     0.17063,     0.18181,       0.193,     0.20327,     0.21344,     0.22299,     0.23283,     0.24099,     0.24737,      0.2569,     0.26426,     0.27147,     0.27955,      0.2848,     0.29165,     0.29946,     0.30702,\n",
       "            0.31624,     0.32266,     0.32856,     0.33579,     0.34347,     0.34858,     0.35443,     0.35931,     0.36449,     0.36964,     0.37471,     0.38107,     0.38501,     0.38881,     0.39351,      0.3982,     0.40025,     0.40482,     0.40946,      0.4141,     0.41833,      0.4229,     0.42681,\n",
       "            0.43002,     0.43378,     0.43747,     0.43981,     0.44217,     0.44713,     0.45077,     0.45278,     0.45595,     0.46076,      0.4624,     0.46481,     0.46947,      0.4731,     0.47792,     0.47974,     0.48435,     0.48547,     0.48894,     0.49168,     0.49987,     0.50158,      0.5064,\n",
       "             0.5095,     0.51191,     0.51447,     0.51756,     0.52051,     0.52292,     0.52785,     0.53251,      0.5358,     0.54077,     0.54356,     0.54762,     0.54833,     0.54932,     0.55211,     0.55579,      0.5618,     0.56338,     0.56635,     0.56855,     0.56997,     0.57105,     0.57289,\n",
       "            0.57513,     0.57761,     0.57927,     0.58154,     0.58465,     0.58693,     0.59077,     0.59189,     0.59597,     0.59805,     0.60075,     0.60444,     0.60438,     0.60509,     0.60732,     0.60932,     0.61019,     0.61179,     0.61304,     0.61385,     0.61509,     0.61617,     0.61794,\n",
       "             0.6203,     0.62505,       0.626,     0.62817,     0.62909,      0.6303,     0.63092,     0.63271,     0.63657,     0.64154,      0.6423,     0.64366,     0.64548,     0.64578,     0.64629,     0.64763,     0.64927,     0.65071,     0.65197,     0.65442,      0.6566,     0.65613,      0.6571,\n",
       "            0.65813,     0.65872,      0.6601,     0.66342,     0.66821,      0.6706,     0.67151,     0.67261,     0.67479,     0.67565,     0.67701,     0.67882,     0.68006,     0.68072,     0.68126,     0.68177,     0.68423,     0.68496,     0.68668,     0.68674,     0.68689,     0.68745,     0.68864,\n",
       "            0.68969,     0.68883,     0.69054,     0.69293,     0.69366,     0.69415,     0.69623,     0.69972,      0.7007,     0.70248,     0.70331,     0.70395,     0.70446,     0.70474,     0.70453,     0.70432,     0.70938,     0.71009,     0.71251,     0.71216,     0.71265,     0.71325,     0.71456,\n",
       "            0.71505,     0.71554,     0.71732,       0.718,     0.72019,     0.72023,     0.72088,     0.72273,      0.7253,     0.72672,      0.7322,     0.73258,     0.73296,     0.73334,     0.73256,     0.73359,     0.73442,     0.73576,     0.73695,      0.7376,     0.74108,     0.74229,     0.74313,\n",
       "            0.74382,     0.74459,      0.7455,     0.74897,     0.74933,     0.74982,     0.75207,     0.75325,      0.7537,     0.75415,     0.75477,       0.756,     0.75691,     0.75761,     0.75818,     0.75872,     0.75914,     0.75956,     0.75998,     0.76332,     0.76755,     0.76819,     0.76814,\n",
       "            0.76888,     0.76958,     0.77021,     0.77097,     0.77354,     0.77325,     0.77451,     0.77431,     0.77453,     0.77475,     0.77498,      0.7752,     0.77542,     0.77564,     0.77607,     0.77656,     0.77705,     0.77788,     0.78011,     0.78089,     0.78168,     0.78264,     0.78392,\n",
       "            0.78413,     0.78536,      0.7876,     0.78936,     0.79267,     0.79342,     0.79386,     0.79431,      0.7947,     0.79496,     0.79523,      0.7955,     0.79576,     0.79603,     0.79701,     0.79697,     0.79762,     0.79828,     0.79819,     0.79854,     0.79935,     0.80002,     0.80063,\n",
       "            0.80257,     0.80651,     0.80751,     0.80943,     0.81082,     0.81144,     0.81206,     0.81294,     0.81349,     0.81326,     0.81299,     0.81477,     0.81613,     0.81755,     0.81733,      0.8176,     0.81786,     0.81813,      0.8184,     0.81867,     0.81941,     0.82114,     0.82186,\n",
       "            0.82262,     0.82344,     0.82381,     0.82364,     0.82375,     0.82441,     0.82508,     0.82552,     0.82592,     0.82632,     0.82671,     0.82711,     0.82752,     0.82793,     0.82834,     0.83034,     0.83135,     0.83255,     0.83543,       0.836,     0.83658,     0.83721,     0.83872,\n",
       "            0.84088,     0.84144,     0.84201,     0.84262,      0.8433,     0.84397,     0.84384,     0.84444,     0.84546,      0.8479,     0.84857,      0.8499,     0.85077,     0.85067,     0.85057,     0.85205,     0.85246,     0.85287,     0.85328,     0.85369,     0.85591,     0.85661,     0.85732,\n",
       "            0.85775,     0.85811,     0.85848,     0.85885,     0.85922,     0.85906,     0.85935,     0.85964,     0.85992,     0.86021,      0.8605,     0.86079,     0.86065,     0.86196,     0.86228,      0.8622,     0.86211,     0.86273,      0.8639,      0.8661,     0.86646,     0.86681,     0.86716,\n",
       "            0.86751,      0.8672,     0.86728,     0.86747,     0.86766,     0.86786,     0.86805,     0.86824,     0.86844,     0.86863,     0.86882,     0.86891,     0.86939,     0.87034,     0.87164,     0.87276,     0.87336,     0.87397,     0.87427,     0.87446,     0.87479,     0.87511,     0.87543,\n",
       "            0.87576,     0.87608,     0.87654,     0.87702,     0.87749,     0.87797,     0.87823,     0.87953,      0.8802,     0.88088,     0.88287,     0.88569,      0.8862,     0.88671,     0.88723,     0.88728,     0.88769,      0.8881,     0.88851,     0.88892,     0.88938,      0.8899,     0.89041,\n",
       "            0.89092,     0.89136,     0.89172,     0.89209,     0.89246,     0.89283,     0.89319,     0.89335,     0.89351,     0.89367,     0.89383,     0.89399,     0.89414,      0.8943,     0.89446,     0.89462,     0.89478,     0.89494,      0.8951,     0.89557,     0.89692,     0.89723,     0.89718,\n",
       "            0.89714,      0.8971,     0.89705,     0.89715,      0.8975,     0.89784,     0.89818,     0.89852,     0.89887,     0.89891,     0.89879,     0.89872,     0.89864,     0.90058,     0.90056,     0.90079,     0.90101,     0.90123,     0.90145,     0.90167,      0.9019,     0.90212,     0.90234,\n",
       "            0.90255,      0.9025,     0.90246,     0.90241,     0.90236,     0.90231,     0.90224,     0.90217,     0.90211,     0.90205,       0.902,     0.90195,     0.90189,     0.90167,     0.90403,     0.90441,     0.90479,     0.90516,     0.90554,     0.90587,     0.90577,     0.90567,     0.90619,\n",
       "            0.90676,     0.90734,      0.9078,     0.90778,     0.90776,     0.90774,     0.90773,     0.90771,     0.90769,     0.90767,     0.90765,     0.90764,     0.90762,      0.9076,     0.90762,     0.90814,     0.90867,     0.90919,     0.90972,     0.90941,     0.90927,     0.90922,     0.90916,\n",
       "             0.9091,     0.91028,     0.91133,     0.91152,     0.91172,     0.91191,      0.9121,     0.91229,     0.91249,     0.91268,     0.91287,     0.91306,     0.91326,     0.91345,     0.91386,     0.91428,     0.91471,     0.91513,     0.91555,     0.91565,     0.91562,      0.9156,     0.91557,\n",
       "            0.91555,     0.91553,      0.9155,     0.91548,     0.91549,     0.91586,     0.91624,     0.91661,     0.91698,     0.91735,     0.91767,     0.91759,     0.91752,     0.91742,     0.91725,     0.91707,     0.91706,     0.91704,     0.91702,     0.91701,     0.91699,     0.91697,     0.91696,\n",
       "            0.91694,     0.91692,     0.91691,     0.91689,     0.91687,     0.91686,     0.91684,     0.91682,      0.9168,     0.91678,     0.91676,     0.91674,     0.91673,     0.91671,     0.91669,     0.91667,      0.9172,     0.91782,     0.91845,     0.91887,     0.91863,      0.9185,     0.91847,\n",
       "            0.91843,      0.9184,     0.91837,     0.91834,      0.9187,     0.91956,     0.92042,      0.9208,     0.92149,     0.92218,     0.92295,     0.92392,     0.92489,     0.92727,     0.92722,     0.92716,     0.92945,     0.92939,     0.92933,     0.92947,     0.93013,     0.93078,     0.93143,\n",
       "            0.93161,     0.93156,     0.93152,     0.93151,     0.93192,     0.93233,     0.93275,     0.93316,     0.93358,     0.93382,     0.93376,      0.9337,     0.93495,     0.93831,     0.93843,      0.9384,     0.93836,     0.93833,     0.93828,     0.93821,     0.93989,     0.94194,     0.94298,\n",
       "            0.94291,     0.94284,     0.94279,     0.94274,     0.94266,     0.94287,     0.94363,     0.94438,     0.94502,     0.94501,     0.94499,     0.94497,     0.94495,     0.94493,     0.94491,      0.9449,     0.94515,     0.94638,     0.94734,     0.94713,     0.94707,     0.94706,     0.94704,\n",
       "            0.94702,       0.947,     0.94698,     0.94697,     0.94694,     0.94679,     0.94675,      0.9467,     0.94665,      0.9466,     0.94654,     0.94648,     0.94642,     0.94637,     0.94634,      0.9463,     0.94627,     0.94624,      0.9462,     0.94616,     0.94612,     0.94855,     0.95006,\n",
       "             0.9509,     0.95082,     0.95072,     0.95057,      0.9513,     0.95218,     0.95305,     0.95297,     0.95285,     0.95349,     0.95474,     0.95528,     0.95519,     0.95511,     0.95774,     0.95768,     0.95759,     0.95738,     0.95735,     0.95732,     0.95729,     0.95721,      0.9571,\n",
       "            0.95703,     0.96253,     0.96247,     0.96238,     0.96281,     0.96323,     0.96366,     0.96409,     0.96451,     0.96494,     0.96491,      0.9647,     0.96463,     0.96458,     0.96454,      0.9645,     0.96443,     0.96432,     0.96407,     0.96405,     0.96403,     0.96401,     0.96398,\n",
       "            0.96396,     0.96389,     0.96379,     0.96364,     0.96357,     0.96342,     0.96335,     0.96381,     0.96623,     0.96609,     0.96894,     0.96889,     0.96884,     0.97238,      0.9752,       0.981,     0.98082,     0.98075,     0.98069,     0.98045,     0.98041,     0.98032,     0.98029,\n",
       "            0.98025,      0.9802,     0.98015,     0.98009,     0.98107,     0.98258,     0.98329,     0.98325,     0.98321,     0.98314,     0.98308,     0.98293,     0.98289,      0.9828,      0.9827,     0.98258,      0.9825,     0.98249,     0.98247,     0.98243,     0.98573,     0.98565,     0.98563,\n",
       "             0.9856,     0.98556,     0.98552,     0.98547,     0.98542,     0.98537,      0.9853,     0.98522,     0.98511,     0.98504,     0.98494,     0.98478,     0.98474,     0.98467,     0.98462,     0.98437,     0.98435,     0.98432,     0.98428,     0.98653,     0.98812,     0.98806,     0.99199,\n",
       "            0.99196,     0.99195,     0.99194,     0.99193,     0.99188,     0.99586,     0.99582,     0.99581,      0.9958,      0.9958,     0.99576,     0.99575,     0.99575,     0.99571,     0.99569,     0.99564,     0.99562,     0.99559,     0.99553,     0.99552,     0.99551,      0.9955,     0.99548,\n",
       "            0.99543,     0.99542,      0.9954,     0.99537,     0.99536,     0.99535,     0.99535,     0.99534,     0.99533,     0.99531,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.94664,     0.94664,     0.94071,     0.93676,     0.93676,     0.93676,     0.93478,     0.93281,     0.93083,     0.92688,     0.92292,     0.92292,     0.92292,     0.92292,     0.92095,     0.92095,     0.91897,       0.917,       0.917,       0.917,       0.917,       0.917,       0.917,\n",
       "              0.917,     0.91304,     0.91304,     0.91107,     0.91107,     0.91107,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90711,     0.90514,     0.90514,     0.90316,     0.90316,     0.90316,     0.90316,     0.90119,     0.90119,     0.90119,     0.90119,\n",
       "            0.90119,     0.90119,     0.90119,     0.90119,     0.90119,     0.90119,     0.90119,     0.89921,     0.89921,     0.89921,     0.89723,     0.89723,     0.89723,     0.89723,     0.89723,     0.89723,     0.89723,     0.89526,     0.89526,     0.89526,     0.89328,      0.8913,      0.8913,\n",
       "             0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,      0.8913,     0.88933,     0.88933,     0.88933,     0.88933,     0.88538,     0.88538,     0.88538,     0.88538,      0.8834,     0.88142,     0.88142,     0.88142,\n",
       "            0.88142,     0.88142,     0.87945,     0.87945,     0.87747,     0.87747,     0.87747,     0.87747,     0.87747,     0.87747,     0.87747,     0.87747,     0.87549,     0.87549,     0.87549,     0.87549,     0.87352,     0.87352,     0.86957,     0.86957,     0.86957,     0.86759,     0.86759,\n",
       "            0.86561,     0.86561,     0.86561,     0.86561,     0.86561,     0.86561,     0.86561,     0.86561,     0.86561,     0.86561,     0.86561,     0.86561,     0.86561,     0.86472,     0.86364,     0.86364,     0.86364,     0.86166,     0.86166,     0.86166,     0.86157,     0.85968,     0.85968,\n",
       "            0.85573,     0.85573,     0.85573,     0.85573,     0.85375,     0.85375,     0.85375,     0.85375,     0.85292,     0.85178,     0.85178,     0.85178,     0.85178,     0.85178,     0.85178,     0.85178,     0.85178,     0.85076,     0.84783,     0.84484,     0.84387,     0.84387,     0.84387,\n",
       "            0.84336,     0.83996,     0.83992,     0.83992,     0.83992,     0.83992,     0.83992,     0.83992,     0.83992,     0.83992,     0.83992,     0.83992,     0.83992,     0.83965,     0.83881,     0.83797,     0.83794,     0.83794,     0.83754,     0.83614,     0.83597,     0.83597,     0.83597,\n",
       "            0.83597,     0.83597,     0.83597,     0.83597,     0.83597,     0.83439,     0.83399,     0.83399,     0.83399,     0.83202,     0.83202,     0.83202,     0.83202,     0.83202,     0.82806,     0.82806,     0.82806,     0.82806,     0.82806,     0.82806,     0.82806,     0.82806,     0.82806,\n",
       "            0.82806,     0.82806,     0.82806,     0.82806,     0.82706,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82609,     0.82517,     0.82411,\n",
       "            0.82411,     0.82411,     0.82411,     0.82411,     0.82357,     0.82222,     0.82138,     0.82016,     0.82016,     0.82016,     0.82016,     0.82016,     0.82016,     0.82016,     0.82016,     0.82016,     0.82016,     0.82016,     0.82016,     0.82016,     0.82016,     0.82016,     0.82016,\n",
       "            0.81838,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81423,     0.81423,     0.81423,     0.81294,     0.81225,     0.81225,     0.81225,     0.81225,\n",
       "            0.81225,     0.81225,     0.81225,     0.81225,     0.81225,     0.81225,     0.81225,     0.81225,     0.81027,     0.80906,      0.8076,     0.80632,     0.80632,     0.80585,     0.80435,     0.80435,     0.80435,     0.80435,     0.80435,     0.80435,     0.80435,     0.80435,     0.80435,\n",
       "            0.80435,     0.80435,     0.80392,     0.80299,     0.80237,     0.80237,     0.80237,     0.80237,     0.80237,     0.80237,     0.80237,     0.80237,     0.80237,     0.80237,     0.80237,     0.80237,     0.80237,     0.80237,     0.80237,     0.80237,     0.80237,     0.80237,     0.80237,\n",
       "            0.80237,     0.80237,     0.80237,     0.80237,     0.80237,     0.80237,     0.80093,      0.8004,      0.8004,      0.8004,      0.8004,      0.8004,     0.79997,     0.79934,     0.79872,     0.79644,     0.79644,     0.79644,     0.79644,     0.79644,     0.79644,     0.79644,     0.79644,\n",
       "            0.79644,     0.79644,     0.79644,     0.79644,     0.79644,     0.79447,     0.79447,     0.79447,     0.79447,     0.79447,     0.79447,     0.79447,      0.7934,     0.79249,     0.79194,     0.79136,     0.79077,     0.79051,     0.79051,     0.79051,     0.79051,     0.79051,     0.79051,\n",
       "            0.79051,     0.78721,     0.78656,     0.78656,     0.78656,     0.78656,     0.78656,     0.78656,     0.78656,     0.78656,     0.78656,       0.786,     0.78458,     0.78458,     0.78458,     0.78458,     0.78458,     0.78458,     0.78328,     0.78261,     0.78261,     0.78261,     0.78261,\n",
       "            0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78261,     0.78063,     0.77866,     0.77866,     0.77866,     0.77866,     0.77866,     0.77866,     0.77866,     0.77866,     0.77668,     0.77668,     0.77668,     0.77668,     0.77668,     0.77668,     0.77668,     0.77668,\n",
       "            0.77668,     0.77668,     0.77668,     0.77668,     0.77668,     0.77668,     0.77668,     0.77668,     0.77668,     0.77668,     0.77668,     0.77668,     0.77668,     0.77668,     0.77668,     0.77668,     0.77668,     0.77668,     0.77668,     0.77668,     0.77668,     0.77641,     0.77604,\n",
       "            0.77567,      0.7753,     0.77493,      0.7747,      0.7747,      0.7747,      0.7747,      0.7747,      0.7747,      0.7732,     0.77219,     0.77159,     0.77098,     0.76978,     0.76877,     0.76877,     0.76877,     0.76877,     0.76877,     0.76877,     0.76877,     0.76877,     0.76877,\n",
       "            0.76876,     0.76834,     0.76793,     0.76752,     0.76711,     0.76665,     0.76606,     0.76548,     0.76489,     0.76442,     0.76396,      0.7635,     0.76305,     0.76113,     0.76087,     0.76087,     0.76087,     0.76087,     0.76087,     0.76079,     0.75988,     0.75897,     0.75889,\n",
       "            0.75889,     0.75889,     0.75886,      0.7587,     0.75854,     0.75837,     0.75821,     0.75805,     0.75788,     0.75772,     0.75756,      0.7574,     0.75723,     0.75707,     0.75692,     0.75692,     0.75692,     0.75692,     0.75692,     0.75387,     0.75265,     0.75213,     0.75161,\n",
       "            0.75108,     0.75099,     0.75099,     0.75099,     0.75099,     0.75099,     0.75099,     0.75099,     0.75099,     0.75099,     0.75099,     0.75099,     0.75099,     0.75099,     0.75099,     0.75099,     0.75099,     0.75099,     0.75099,     0.75082,     0.75059,     0.75036,     0.75013,\n",
       "             0.7499,     0.74968,     0.74945,     0.74922,     0.74901,     0.74901,     0.74901,     0.74901,     0.74901,     0.74901,     0.74893,     0.74821,     0.74749,     0.74644,     0.74481,     0.74308,     0.74292,     0.74276,     0.74259,     0.74243,     0.74227,     0.74211,     0.74195,\n",
       "            0.74179,     0.74162,     0.74146,      0.7413,     0.74114,     0.74096,     0.74078,      0.7406,     0.74042,     0.74024,     0.74006,     0.73988,      0.7397,     0.73952,     0.73934,     0.73916,     0.73913,     0.73913,     0.73913,      0.7386,     0.73631,       0.735,     0.73468,\n",
       "            0.73435,     0.73403,      0.7337,     0.73338,      0.7332,      0.7332,      0.7332,     0.73123,     0.73123,     0.73123,     0.73123,     0.73123,     0.73123,     0.73075,     0.73015,     0.72956,     0.72897,     0.72835,     0.72772,     0.72727,     0.72727,     0.72727,     0.72727,\n",
       "             0.7269,     0.72635,      0.7258,      0.7253,      0.7253,      0.7253,      0.7253,      0.7253,      0.7253,     0.72504,     0.72435,     0.72365,     0.72332,     0.72332,     0.72292,      0.7225,     0.72208,     0.72166,      0.7211,     0.72012,     0.71937,     0.71937,     0.71908,\n",
       "            0.71808,     0.71719,     0.71653,     0.71587,     0.71472,     0.71344,     0.71344,     0.71344,      0.7134,     0.71315,      0.7129,     0.71265,     0.71241,     0.71216,     0.71191,     0.71166,     0.71146,     0.71146,     0.71103,     0.70807,     0.70729,     0.70703,     0.70678,\n",
       "            0.70653,     0.70627,     0.70602,     0.70577,     0.70534,     0.70331,     0.70268,     0.70205,     0.70138,     0.70062,     0.69986,     0.69903,     0.69816,     0.69745,     0.69701,     0.69657,     0.69612,     0.69568,     0.69512,     0.69456,       0.694,     0.69231,     0.68972,\n",
       "            0.68897,     0.68775,     0.68626,     0.68414,     0.68379,     0.68379,     0.68379,     0.68083,     0.67893,     0.67787,     0.67787,     0.67542,     0.67398,      0.6728,     0.67185,     0.67083,     0.66936,      0.6659,     0.66539,     0.66489,     0.66438,     0.66319,     0.66137,\n",
       "            0.66021,        0.66,     0.65878,     0.65415,     0.65415,     0.65415,     0.65415,     0.65415,     0.65415,     0.65415,     0.65219,     0.64815,     0.64672,     0.64579,      0.6451,     0.64442,     0.64308,      0.6409,     0.63636,     0.63595,     0.63555,     0.63514,     0.63474,\n",
       "            0.63424,     0.63307,      0.6312,     0.62846,     0.62727,     0.62457,     0.62342,     0.62253,     0.62206,      0.6194,     0.61645,     0.61551,     0.61445,     0.61265,     0.61265,     0.61233,      0.6064,     0.60403,     0.60212,     0.59476,     0.59339,     0.59063,     0.58971,\n",
       "            0.58868,     0.58711,     0.58564,     0.58376,       0.583,       0.583,     0.58149,     0.58008,     0.57852,     0.57615,     0.57399,      0.5691,     0.56777,     0.56468,      0.5613,     0.55745,     0.55493,     0.55438,     0.55384,      0.5524,     0.54624,     0.54294,     0.54214,\n",
       "             0.5412,     0.53959,     0.53804,     0.53632,     0.53433,     0.53239,     0.52991,     0.52702,     0.52302,     0.52038,     0.51692,     0.51152,     0.50997,     0.50777,      0.5062,      0.4979,     0.49708,     0.49626,     0.49494,     0.49407,     0.49299,     0.49047,     0.48934,\n",
       "            0.48786,     0.48729,     0.48672,     0.48599,     0.48278,     0.47485,     0.47113,     0.46988,      0.4691,     0.46805,     0.46416,     0.46339,     0.46262,     0.45922,     0.45684,     0.45105,     0.44919,     0.44604,      0.4406,     0.43923,      0.4382,     0.43734,     0.43538,\n",
       "            0.43059,     0.42943,     0.42751,     0.42474,     0.42409,     0.42345,     0.42279,     0.42204,     0.42128,     0.41917,     0.41536,     0.41032,     0.40855,     0.40648,     0.40548,     0.40079,     0.39902,     0.39773,     0.39428,        0.39,     0.38592,     0.38419,     0.38008,\n",
       "            0.37727,      0.3758,     0.37106,     0.36984,     0.36854,     0.36734,     0.36645,     0.36554,     0.36415,      0.3629,     0.36173,     0.35884,     0.35699,     0.35527,     0.35332,     0.35267,     0.35203,     0.35048,      0.3483,     0.34633,     0.34453,     0.34012,     0.33863,\n",
       "             0.3374,     0.33632,     0.33199,     0.33013,      0.3259,      0.3245,     0.32155,      0.3177,     0.31693,     0.31604,      0.3132,     0.30935,     0.30675,     0.30222,     0.30134,     0.30046,     0.29721,     0.29319,     0.28734,     0.28403,     0.28326,     0.28173,     0.27399,\n",
       "            0.27126,     0.26802,     0.26284,     0.26215,     0.26146,     0.25943,     0.25661,     0.25154,      0.2495,     0.24466,     0.24147,     0.23727,     0.23468,     0.22853,     0.22405,     0.21516,     0.21261,     0.20565,     0.19137,      0.1899,      0.1854,     0.18205,     0.17115,\n",
       "            0.16856,     0.16613,     0.15776,     0.15369,     0.15077,     0.14736,     0.14068,     0.13629,     0.13116,     0.12673,     0.11599,      0.1118,      0.1084,     0.10707,      0.1043,    0.091375,    0.085536,     0.07879,    0.067252,    0.063426,    0.058691,    0.055144,    0.051051,\n",
       "           0.044375,    0.039435,    0.038045,     0.03404,    0.031662,    0.027476,     0.02574,    0.024748,    0.023777,    0.019407,    0.017661,    0.016644,    0.015475,    0.013538,   0.0099268,   0.0078141,   0.0074525,    0.007091,   0.0067295,   0.0063679,   0.0060064,   0.0040781,   0.0034361,\n",
       "          0.0028905,   0.0023449,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: 0.5719363363545658\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([     0.5392])\n",
       "names: {0: 'face'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.8970526606293974, 'metrics/recall(B)': 0.7749346315516216, 'metrics/mAP50(B)': 0.8665746877098939, 'metrics/mAP50-95(B)': 0.5391987417595293, 'fitness': 0.5719363363545658}\n",
       "save_dir: WindowsPath('runs/detect/train4')\n",
       "speed: {'preprocess': 2.838979499616873, 'inference': 148.59350343768514, 'loss': 0.0, 'postprocess': 0.40683496310916284}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-10 03:48:13,291 - clearml.Task - INFO - Completed model upload to https://files.clear.ml/YOLOv8/train4.2074b985d5d74291aeb9a8c2e7c6d75f/models/best.pt\n",
      "Nvidia driver cannot export utilization, pushing fixed value 100\n",
      "2024-07-10 13:18:34,312 - clearml.Task - WARNING - ### TASK STOPPED - USER ABORTED - STATUS CHANGED ###\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(r\"C:\\Users\\zanyi\\OneDrive\\Git hub\\Ai\\School Anniversary\\EyeAssist\\faceDetection\\runs\\detect\\train4\\weights\\last.pt\")\n",
    "model.train(resume=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "v = [1,2,1,1]\n",
    "print(v.count(1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
